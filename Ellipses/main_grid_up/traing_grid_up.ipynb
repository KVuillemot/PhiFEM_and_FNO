{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from utils import *\n",
    "import seaborn as sns\n",
    "import operator\n",
    "from functools import reduce\n",
    "from losses import Loss\n",
    "from scheduler import ReduceLROnPlateau_perso\n",
    "import gc\n",
    "from grid_up import UpAgent, GridupTrainer\n",
    "import torchvision\n",
    "\n",
    "seed = 2102\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "sns.set_theme()\n",
    "sns.set_context(\"paper\")\n",
    "sns.set(rc={\"xtick.bottom\": True, \"ytick.left\": True})\n",
    "colors = sns.color_palette(\"mako\").as_hex()\n",
    "my_cmap = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_domain_and_border():\n",
    "    \"\"\"\n",
    "    Test function for domain_and_border.\n",
    "\n",
    "    Loads a phi tensor from file and computes domain and boundary tensors.\n",
    "    Displays visualizations of the domain and boundaries.\n",
    "    \"\"\"\n",
    "    phi = torch.tensor(np.load(\"../data/Phi.npy\"), dtype=torch.float32)[None, 20, :, :]\n",
    "    tmp_loss = Loss()\n",
    "    domain, domain_1, domain_2 = tmp_loss.compute_boundaries(phi, 2)\n",
    "    domain, domain_1, domain_2 = (\n",
    "        domain.int().numpy()[0, :, :],\n",
    "        domain_1.int().numpy()[0, :, :],\n",
    "        domain_2.int().numpy()[0, :, :],\n",
    "    )\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(domain + domain_1 + domain_2, cmap=\"viridis\", origin=\"lower\")\n",
    "    plt.colorbar()\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def test_data():\n",
    "    \"\"\"\n",
    "    Test function for loading and visualizing data.\n",
    "\n",
    "    Loads tensors F, Phi, G, and W from file and displays visualizations.\n",
    "    \"\"\"\n",
    "\n",
    "    phi = torch.tensor(np.load(\"../data/Phi.npy\"), dtype=torch.float32)[10]\n",
    "    F = torch.tensor(np.load(\"../data/F.npy\"), dtype=torch.float32)[10]\n",
    "    W = torch.tensor(np.load(\"../data/W.npy\"), dtype=torch.float32)[10]\n",
    "    G = torch.tensor(np.load(\"../data/G.npy\"), dtype=torch.float32)[10]\n",
    "\n",
    "    domain, boundary = domain_and_border(phi.shape[0], phi)\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.imshow(domain, cmap=my_cmap, origin=\"lower\")\n",
    "    plt.colorbar(shrink=0.6)\n",
    "    plt.grid(False)\n",
    "    plt.subplot(2, 3, 2)\n",
    "    plt.imshow(boundary, cmap=my_cmap, origin=\"lower\")\n",
    "    plt.colorbar(shrink=0.6)\n",
    "    plt.grid(False)\n",
    "    plt.subplot(2, 3, 3)\n",
    "    plt.imshow(F * domain, cmap=my_cmap, origin=\"lower\")\n",
    "    plt.colorbar(shrink=0.6)\n",
    "    plt.title(\"F\")\n",
    "    plt.grid(False)\n",
    "    plt.subplot(2, 3, 4)\n",
    "    plt.imshow(G * domain, cmap=my_cmap, origin=\"lower\")\n",
    "    plt.colorbar(shrink=0.6)\n",
    "    plt.title(\"G\")\n",
    "    plt.grid(False)\n",
    "    plt.subplot(2, 3, 5)\n",
    "    plt.imshow(W * domain, cmap=my_cmap, origin=\"lower\")\n",
    "    plt.colorbar(shrink=0.6)\n",
    "    plt.title(\"W\")\n",
    "    plt.grid(False)\n",
    "    plt.subplot(2, 3, 6)\n",
    "    plt.imshow((W * phi + G) * domain, cmap=my_cmap, origin=\"lower\")\n",
    "    plt.colorbar(shrink=0.6)\n",
    "    plt.title(\"U\")\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "class UnitGaussianNormalizer(object):\n",
    "    \"\"\"\n",
    "    Class for normalizing and denormalizing tensors using unit Gaussian normalization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x, eps=0.00001):\n",
    "        \"\"\"\n",
    "        Initializes the normalizer.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor to compute mean and std.\n",
    "            eps (float): Small value to avoid division by zero.\n",
    "        \"\"\"\n",
    "        super(UnitGaussianNormalizer, self).__init__()\n",
    "\n",
    "        self.means = torch.mean(x, dim=(0, 2, 3))\n",
    "        self.stds = torch.std(x, dim=(0, 2, 3))\n",
    "        self.eps = eps\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        Normalizes the input tensor.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor to be normalized.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Normalized tensor.\n",
    "        \"\"\"\n",
    "        x = (x - self.means[None, :, None, None].to(x.device)) / (\n",
    "            self.stds[None, :, None, None].to(x.device) + self.eps\n",
    "        )\n",
    "        return x\n",
    "\n",
    "    def decode(self, x):\n",
    "        \"\"\"\n",
    "        Denormalizes the input tensor.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor to be denormalized.\n",
    "            sample_idx (None): Placeholder for compatibility.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Denormalized tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        stds = (self.stds + self.eps).to(x.device)  # n\n",
    "        means = self.means.to(x.device)\n",
    "        x = (x * stds[None, :, None, None]) + means[None, :, None, None]\n",
    "        return x\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    DataLoader class for loading and preprocessing input data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, small_data=False, dtype=torch.float32):\n",
    "        \"\"\"\n",
    "        Initializes the DataLoader.\n",
    "\n",
    "        Args:\n",
    "            small_data (bool): Whether to use a smaller subset of the data.\n",
    "            dtype (torch.dtype): Data type of the tensors.\n",
    "        \"\"\"\n",
    "\n",
    "        F = torch.tensor(np.load(f\"../data/F.npy\"), dtype=dtype)\n",
    "        nb_vert = F.shape[1]\n",
    "        self.nb_vert = nb_vert\n",
    "        Phi = torch.tensor(np.load(f\"../data/Phi.npy\"), dtype=dtype)\n",
    "        G = torch.tensor(\n",
    "            np.load(f\"../data/G.npy\"),\n",
    "            dtype=dtype,\n",
    "        )\n",
    "        Y = torch.tensor(np.load(f\"../data/W.npy\"), dtype=dtype)[:, None, :, :]\n",
    "\n",
    "        if small_data:\n",
    "            data_size = 120\n",
    "        else:\n",
    "            data_size = F.shape[0]\n",
    "\n",
    "        if small_data:\n",
    "            F = F[:data_size]\n",
    "            Phi = Phi[:data_size]\n",
    "            G = G[:data_size]\n",
    "            Y = Y[:data_size]\n",
    "\n",
    "        nb_vert = F.shape[1]\n",
    "\n",
    "        X = torch.stack([F, Phi, G], dim=1)\n",
    "        self.input_shape = (None, X.shape[1], X.shape[2], X.shape[3])\n",
    "        if small_data:\n",
    "            nb_val = 20\n",
    "        else:\n",
    "            nb_val = 300  # data_size // 8\n",
    "        nb_train = data_size - nb_val\n",
    "        print(\"data_size,nb_val,nb_train:\", data_size, nb_val, nb_train)\n",
    "        print(\"data shape:\", self.input_shape)\n",
    "\n",
    "        def separe(A):\n",
    "            return A[:nb_train], A[nb_train:]\n",
    "\n",
    "        self.X_train, self.X_val = separe(X)\n",
    "        self.Y_train, self.Y_val = separe(Y)\n",
    "\n",
    "        self.x_normalizer = UnitGaussianNormalizer(self.X_train)\n",
    "        self.X_train_normed = self.x_normalizer.encode(self.X_train)\n",
    "        self.X_val_normed = self.x_normalizer.encode(self.X_val)\n",
    "\n",
    "        self.y_normalizer = UnitGaussianNormalizer(self.Y_train)\n",
    "        self.Y_train_normed = self.y_normalizer.encode(self.Y_train)\n",
    "        self.Y_val_normed = self.y_normalizer.encode(self.Y_val)\n",
    "\n",
    "        self.nb_vert = self.X_train.shape[1]\n",
    "        self.nb_train, self.nb_val = nb_train, nb_val\n",
    "\n",
    "\n",
    "def test_DataLoader():\n",
    "    data = DataLoader()\n",
    "    print(\"X_train\", data.X_train.shape)\n",
    "    print(\"X_val\", data.X_val.shape)\n",
    "    print(\"Y_train\", data.Y_train.shape)\n",
    "    print(\"Y_val\", data.Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralConv2d(nn.Module):\n",
    "    \"\"\"\n",
    "    SpectralConv2d: Complex-valued 2D convolutional layer using spectral convolution.\n",
    "\n",
    "    This layer applies a 2D convolution in the frequency domain using complex-valued weights.\n",
    "    The weights are parameterized by complex-valued tensors and are used to perform spectral\n",
    "    convolution via element-wise multiplication in the Fourier space.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of input channels.\n",
    "        out_channels (int): Number of output channels.\n",
    "        modes (int): Number of Fourier modes used for the convolution.\n",
    "\n",
    "    Attributes:\n",
    "        in_channels (int): Number of input channels.\n",
    "        out_channels (int): Number of output channels.\n",
    "        modes (int): Number of Fourier modes used for the convolution.\n",
    "        scale (float): Scaling factor for the weights initialization.\n",
    "        weights1 (nn.Parameter): Learnable complex-valued weights for the first convolution.\n",
    "        weights2 (nn.Parameter): Learnable complex-valued weights for the second convolution.\n",
    "\n",
    "    Methods:\n",
    "        compl_mul2d(input, weights):\n",
    "            Perform complex multiplication of 2D tensors.\n",
    "\n",
    "        forward(x):\n",
    "            Forward pass of the spectral convolution layer.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, modes):\n",
    "        \"\"\"\n",
    "        Initializes the SpectralConv2d layer.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "            modes (int): Number of Fourier modes used for the convolution.\n",
    "        \"\"\"\n",
    "        super(SpectralConv2d, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes = modes\n",
    "        self.scale = 1 / (in_channels * out_channels)\n",
    "        self.weights1 = nn.Parameter(\n",
    "            self.scale\n",
    "            * torch.rand(\n",
    "                self.in_channels,\n",
    "                self.out_channels,\n",
    "                self.modes,\n",
    "                self.modes,\n",
    "                dtype=torch.cfloat,\n",
    "            )\n",
    "        )\n",
    "        self.weights2 = nn.Parameter(\n",
    "            self.scale\n",
    "            * torch.rand(\n",
    "                self.in_channels,\n",
    "                self.out_channels,\n",
    "                self.modes,\n",
    "                self.modes,\n",
    "                dtype=torch.cfloat,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def compl_mul2d(self, input, weights):\n",
    "        \"\"\"\n",
    "        Perform complex multiplication of 2D tensors.\n",
    "\n",
    "        Args:\n",
    "            input (torch.Tensor): Input tensor with shape (batch, in_channel, x, y).\n",
    "            weights (nn.Parameter): Complex-valued weights with shape\n",
    "                                   (in_channel, out_channel, x, y).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Result of complex multiplication with shape\n",
    "                          (batch, out_channel, x, y).\n",
    "        \"\"\"\n",
    "        # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
    "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the spectral convolution layer.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor with shape (batch, in_channel, x, y).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after spectral convolution with shape\n",
    "                          (batch, out_channel, x, y).\n",
    "        \"\"\"\n",
    "\n",
    "        batchsize = x.shape[0]\n",
    "\n",
    "        x_ft = torch.fft.rfft2(x)\n",
    "\n",
    "        factor1 = self.compl_mul2d(\n",
    "            x_ft[:, :, : self.modes, : self.modes],\n",
    "            self.weights1,\n",
    "        )\n",
    "        factor2 = self.compl_mul2d(\n",
    "            x_ft[:, :, -self.modes :, : self.modes],\n",
    "            self.weights2,\n",
    "        )\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(\n",
    "            batchsize,\n",
    "            self.out_channels,\n",
    "            x.size(-2),\n",
    "            x.size(-1) // 2 + 1,\n",
    "            dtype=torch.cfloat,\n",
    "            device=x.device,\n",
    "        )\n",
    "        out_ft[:, :, : self.modes, : self.modes] = factor1\n",
    "        out_ft[:, :, -self.modes :, : self.modes] = factor2\n",
    "\n",
    "        # Return to physical space\n",
    "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class FNO2dLayer(nn.Module):\n",
    "    def __init__(self, conv, bias):\n",
    "        super(FNO2dLayer, self).__init__()\n",
    "\n",
    "        self.conv = conv\n",
    "        self.bias = bias\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv(x)\n",
    "        x2 = self.bias(x)\n",
    "        return x1 + x2\n",
    "\n",
    "\n",
    "class FNO2d(nn.Module):\n",
    "    \"\"\"\n",
    "    FNO2d: Neural network for solving partial differential equations (PDEs) using Fourier Neural Operators in 2D.\n",
    "\n",
    "    This network consists of multiple layers, each comprising a spectral convolution (SpectralConv2d)\n",
    "    followed by a bias term (nn.Conv2d), with activation functions applied in between.\n",
    "    The architecture is designed for solving PDEs on 2D domains.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of input channels.\n",
    "        modes (int): Number of Fourier modes to consider.\n",
    "        width (int): Width of the network layers.\n",
    "        pad_prop (float): Proportion of padding to be applied to the input.\n",
    "        nb_layers (int): Number of layers in the network.\n",
    "        pad_mode (str): Padding mode for convolutional layers.\n",
    "        activation (str): Activation function to be used. Supported options: 'relu', 'tanh', 'elu', 'gelu'.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        modes,\n",
    "        width,\n",
    "        pad_prop=0.05,\n",
    "        nb_layers=4,\n",
    "        pad_mode=\"reflect\",\n",
    "        activation=\"gelu\",\n",
    "    ):\n",
    "        super(FNO2d, self).__init__()\n",
    "\n",
    "        self.modes = modes\n",
    "        self.width = width\n",
    "        self.pad_prop = pad_prop\n",
    "        self.pad_mode = pad_mode\n",
    "        assert (\n",
    "            self.pad_mode == \"reflect\"\n",
    "            or self.pad_mode == \"constant\"\n",
    "            or self.pad_mode == \"replicate\"\n",
    "            or self.pad_mode == \"one_side_reflect\"\n",
    "        )\n",
    "        if activation == \"relu\":\n",
    "            self.activation = F.relu\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = F.tanh\n",
    "        elif activation == \"elu\":\n",
    "            self.activation = F.elu\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation = F.gelu\n",
    "        else:\n",
    "            raise Exception(f\"activation function:{activation} not allowed\")\n",
    "        self.in_channels = in_channels\n",
    "        self.fc0 = nn.Conv2d(\n",
    "            in_channels + 2, self.width, 1\n",
    "        )  # input channel is 5: (f(x,y), phi(x,y), g(x,y), x, y)\n",
    "        self.nb_layers = nb_layers\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(self.nb_layers):\n",
    "            self.layers.append(\n",
    "                FNO2dLayer(\n",
    "                    SpectralConv2d(self.width, self.width, self.modes),\n",
    "                    nn.Conv2d(self.width, self.width, 1),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.fc1 = nn.Conv2d(self.width, 128, 1)\n",
    "        self.fc2 = nn.Conv2d(128, 1, 1)\n",
    "\n",
    "    def get_grid(self, shape, device):\n",
    "        \"\"\"\n",
    "        Generate a grid of coordinates based on the input shape.\n",
    "\n",
    "        Args:\n",
    "            shape (torch.Size): Shape of the input tensor.\n",
    "            device (torch.device): Device on which the grid tensor should be created.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Grid tensor with coordinates.\n",
    "        \"\"\"\n",
    "        batchsize, size_x, size_y = shape[0], shape[2], shape[3]\n",
    "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
    "        gridx = gridx.reshape(1, 1, size_x, 1).repeat([batchsize, 1, 1, size_y])\n",
    "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
    "        gridy = gridy.reshape(1, 1, 1, size_y).repeat([batchsize, 1, size_x, 1])\n",
    "        return torch.cat((gridx, gridy), dim=1).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the FNO2d network.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after passing through the network.\n",
    "        \"\"\"\n",
    "        self.padding = int(x.shape[2] * self.pad_prop)\n",
    "        grid = self.get_grid(x.shape, x.device)\n",
    "        x = torch.cat((x, grid), dim=1)\n",
    "        x = self.fc0(x)\n",
    "        if self.padding != 0 and self.pad_mode != \"one_side_reflect\":\n",
    "            x = F.pad(\n",
    "                x,\n",
    "                [self.padding, self.padding, self.padding, self.padding],\n",
    "                mode=self.pad_mode,\n",
    "            )\n",
    "        elif self.padding != 0 and self.pad_mode == \"one_side_reflect\":\n",
    "            x = F.pad(\n",
    "                x,\n",
    "                [0, self.padding, 0, self.padding],\n",
    "                mode=\"reflect\",\n",
    "            )\n",
    "        for i in range(self.nb_layers):\n",
    "            x = self.layers[i](x)\n",
    "            if i < self.nb_layers - 1:\n",
    "                x = self.activation(x)\n",
    "        if self.padding != 0 and self.pad_mode != \"one_side_reflect\":\n",
    "            x = x[..., self.padding : -self.padding, self.padding : -self.padding]\n",
    "        elif self.padding != 0 and self.pad_mode == \"one_side_reflect\":\n",
    "            x = x[..., : -self.padding, : -self.padding]\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def count_params(model):\n",
    "    c = 0\n",
    "    for p in list(model.parameters()):\n",
    "        c += reduce(operator.mul, list(p.size()))\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(UpAgent):\n",
    "    \"\"\"\n",
    "    Agent: A class representing an agent for training and validating a FNO model.\n",
    "\n",
    "    This agent is designed for solving partial differential equations (PDEs) using a Fourier Neural Operator\n",
    "    in 2D. It includes functionalities for training the model, validating its performance, and saving the best model.\n",
    "\n",
    "    Args:\n",
    "        data (object): An instance of the data class containing training and validation data.\n",
    "        level (int): loss level for training. Defaults to 2.\n",
    "        relative (bool): If True, use relative error in loss calculation. Defaults to True.\n",
    "        squared (bool): If True, use squared error in loss calculation. Defaults to False.\n",
    "        initial_lr (float): Initial learning rate for the optimizer. Defaults to 5e-3.\n",
    "        n_modes (int): Number of Fourier modes to consider. Defaults to 10.\n",
    "        width (int): Width of the network layers. Defaults to 20.\n",
    "        batch_size (int): Batch size for training. Defaults to 64.\n",
    "        l2_lambda (float): L2 regularization strength. Defaults to 1e-3.\n",
    "        pad_prop (float): Proportion of padding to be applied to the input. Defaults to 0.0.\n",
    "        pad_mode (str): Padding mode for convolutional layers. Defaults to \"one_side_reflect\".\n",
    "        nb_layers (int): Number of layers in the network. Defaults to 4.\n",
    "        activation (str): Activation function to be used. Supported options: 'relu', 'tanh', 'elu', 'gelu'.\n",
    "            Defaults to 'gelu'.\n",
    "\n",
    "    Attributes:\n",
    "        data (object): An instance of the data class containing training and validation data.\n",
    "        level (int): PDE level for training.\n",
    "        relative (bool): If True, use relative error in loss calculation.\n",
    "        squared (bool): If True, use squared error in loss calculation.\n",
    "        initial_lr (float): Initial learning rate for the optimizer.\n",
    "        n_modes (int): Number of Fourier modes to consider.\n",
    "        width (int): Width of the network layers.\n",
    "        batch_size (int): Batch size for training.\n",
    "        l2_lambda (float): L2 regularization strength.\n",
    "        pad_prop (float): Proportion of padding to be applied to the input.\n",
    "        pad_mode (str): Padding mode for convolutional layers.\n",
    "        nb_layers (int): Number of layers in the network.\n",
    "        activation (str): Activation function used in the network.\n",
    "        X_train (torch.Tensor): Training input data.\n",
    "        X_train_normed (torch.Tensor): Normalized training input data.\n",
    "        Y_train (torch.Tensor): Training output data.\n",
    "        X_val (torch.Tensor): Validation input data.\n",
    "        X_val_normed (torch.Tensor): Normalized validation input data.\n",
    "        Y_val (torch.Tensor): Validation output data.\n",
    "        nb_train_data (int): Number of training data points.\n",
    "        nb_val_data (int): Number of validation data points.\n",
    "        model (FNO2d): Neural network model for solving PDEs.\n",
    "        optimizer (torch.optim.Adam): Optimizer for training the model.\n",
    "        scheduler (ReduceLROnPlateau_perso): Learning rate scheduler.\n",
    "        loss_function (Loss): Loss function for training.\n",
    "        nb_batch (int): Number of batches in one training epoch.\n",
    "        test_batch_size (int): Batch size for evaluating losses on a subset of data during training.\n",
    "        losses (list): List to store training losses during training.\n",
    "        losses_dict (list): List to store dictionary-based losses during training.\n",
    "        losses_array (list): List to store array-based losses during training.\n",
    "        nb_train_epochs (int): Number of training epochs completed.\n",
    "        nweights (int): Number of learnable parameters in the model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        level,\n",
    "        initial_lr,\n",
    "        n_modes,\n",
    "        width,\n",
    "        batch_size,\n",
    "        l2_lambda,\n",
    "        pad_prop,\n",
    "        pad_mode,\n",
    "        essaie,\n",
    "        data,\n",
    "    ):\n",
    "        self.data = data\n",
    "        self.level = level\n",
    "        self.relative = True\n",
    "        self.squared = False\n",
    "        self.initial_lr = initial_lr\n",
    "        self.n_modes = n_modes\n",
    "        self.width = width\n",
    "        self.batch_size = batch_size\n",
    "        self.l2_lambda = l2_lambda\n",
    "        self.pad_prop = pad_prop\n",
    "        self.pad_mode = pad_mode\n",
    "        self.nb_layers = 4\n",
    "        self.activation = \"gelu\"\n",
    "        self.X_train = self.data.X_train\n",
    "        self.X_train_normed = self.data.X_train_normed\n",
    "        self.Y_train = self.data.Y_train\n",
    "        self.X_val = self.data.X_val\n",
    "        self.X_val_normed = self.data.X_val_normed\n",
    "        self.Y_val = self.data.Y_val\n",
    "\n",
    "        nb_data_train = self.X_train.shape[0]\n",
    "        in_channels = self.X_train.shape[1]\n",
    "\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        if not (self.device == self.Y_train.device):\n",
    "            self.X_train = self.data.X_train.to(self.device)\n",
    "            self.X_train_normed = self.data.X_train_normed.to(self.device)\n",
    "            self.Y_train = self.data.Y_train.to(self.device)\n",
    "            self.X_val = self.data.X_val.to(self.device)\n",
    "            self.X_val_normed = self.data.X_val_normed.to(self.device)\n",
    "            self.Y_val = self.data.Y_val.to(self.device)\n",
    "\n",
    "        self.nb_train_data = self.X_train.shape[0]\n",
    "        self.nb_val_data = self.X_val.shape[0]\n",
    "\n",
    "        self.model = FNO2d(\n",
    "            in_channels,\n",
    "            modes=self.n_modes,\n",
    "            width=self.width,\n",
    "            pad_prop=self.pad_prop,\n",
    "            pad_mode=self.pad_mode,\n",
    "            nb_layers=self.nb_layers,\n",
    "            activation=self.activation,\n",
    "        ).to(self.device)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), self.initial_lr)\n",
    "        self.scheduler = ReduceLROnPlateau_perso(\n",
    "            self.optimizer,\n",
    "            patience=20,\n",
    "            factor=0.7,\n",
    "            cooldown=5,\n",
    "            min_lr=1e-5,\n",
    "        )\n",
    "        self.loss_function = Loss()\n",
    "        self.nb_batch = nb_data_train // self.batch_size\n",
    "        self.test_batch_size = 300\n",
    "        if self.test_batch_size > self.X_val.shape[0]:\n",
    "            self.test_batch_size = self.X_val.shape[0]\n",
    "        self.losses = []\n",
    "        self.losses_dict = []\n",
    "        self.losses_array = []\n",
    "        self.nb_train_epochs = 0\n",
    "        self.nweights = 0\n",
    "        for name, weights in self.model.named_parameters():\n",
    "            if \"bias\" not in name:\n",
    "                self.nweights = self.nweights + weights.numel()\n",
    "\n",
    "    def fit_train_case(self, case):\n",
    "        \"\"\"\n",
    "        Train the model for one epoch using the training data.\n",
    "\n",
    "        Updates the model parameters based on the training data and computes the training loss.\n",
    "        \"\"\"\n",
    "        self.nb_train_epochs += 1\n",
    "        if self.nb_train_epochs % 200 == 0:\n",
    "            print(f\"Epoch : {self.nb_train_epochs}\")\n",
    "        X_train, Y_train = self.X_train, self.Y_train\n",
    "        X_train_normed = self.X_train_normed\n",
    "        rand_i = torch.randperm(X_train.shape[0])\n",
    "\n",
    "        X = X_train_normed[rand_i]\n",
    "        Y = Y_train[rand_i]\n",
    "        X_denormed = X_train[rand_i]\n",
    "        self.model.train()\n",
    "        loss_i = 0.0\n",
    "        for i in range(self.nb_batch):\n",
    "            sli = slice(i * self.batch_size, (i + 1) * self.batch_size)\n",
    "            x, y_true = X[sli], Y[sli]\n",
    "            self.optimizer.zero_grad()\n",
    "            y_pred_normed = self.model(x)\n",
    "            y_pred = self.data.y_normalizer.decode(y_pred_normed)\n",
    "            loss = self.loss_function(\n",
    "                X_denormed[sli],\n",
    "                y_pred,\n",
    "                y_true,\n",
    "                mode=\"train\",\n",
    "                level=self.level,\n",
    "                relative=self.relative,\n",
    "                squared=self.squared,\n",
    "            )\n",
    "            L2_term = torch.tensor(0.0, requires_grad=False)\n",
    "            for name, weights in self.model.named_parameters():\n",
    "                if \"bias\" not in name:\n",
    "                    weights_sum_sq = torch.sum((weights * weights.conj()).real)\n",
    "                    L2_term = L2_term + weights_sum_sq\n",
    "            L2_term = L2_term / 2\n",
    "            loss = loss + L2_term * self.l2_lambda\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            loss_i += loss / self.batch_size\n",
    "        self.losses.append(loss / self.nb_batch)\n",
    "\n",
    "        validation_loss = self.validate()\n",
    "        self.scheduler.step(validation_loss)\n",
    "        if self.scheduler.lr_has_changed:\n",
    "            if self.scheduler.patience <= 60:\n",
    "                self.scheduler.patience = int(self.scheduler.patience * 1.5)\n",
    "            print(f\"{self.scheduler.patience = } {self.scheduler._last_lr[-1] = :.3e}\")\n",
    "\n",
    "    def validate(self):\n",
    "        \"\"\"\n",
    "        Validate the model on the validation data.\n",
    "\n",
    "        Returns:\n",
    "            float: Mean validation loss on a part of the validation dataset.\n",
    "        \"\"\"\n",
    "        indices = torch.randperm(self.X_val.shape[0])[: self.test_batch_size]\n",
    "        x, y_true = self.X_val_normed[indices], self.Y_val[indices]\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred_normed = self.model(x)\n",
    "            y_pred = self.data.y_normalizer.decode(y_pred_normed)\n",
    "            loss_v, loss_0_v, loss_1_v, loss_2_v = self.loss_function(\n",
    "                self.X_val[indices],\n",
    "                y_pred,\n",
    "                y_true,\n",
    "                mode=\"val\",\n",
    "                level=self.level,\n",
    "                relative=self.relative,\n",
    "                squared=self.squared,\n",
    "            )\n",
    "        return loss_v / self.test_batch_size\n",
    "\n",
    "    def metrics_test_case(self, case):\n",
    "        \"\"\"\n",
    "        Evaluate losses on a subset of training and validation data.\n",
    "\n",
    "        Returns:\n",
    "            float: Mean validation losses per dataset.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            # check a part of the validation sample\n",
    "            indices = torch.randperm(self.X_val.shape[0])[: self.test_batch_size]\n",
    "            x, y_true = self.X_val_normed[indices], self.Y_val[indices]\n",
    "            y_pred_normed = self.model(x)\n",
    "            y_pred = self.data.y_normalizer.decode(y_pred_normed)\n",
    "            loss_v, loss_0_v, loss_1_v, loss_2_v = self.loss_function(\n",
    "                self.X_val[indices],\n",
    "                y_pred,\n",
    "                y_true,\n",
    "                mode=\"val\",\n",
    "                level=2,\n",
    "                relative=True,\n",
    "                squared=False,\n",
    "            )\n",
    "\n",
    "        accuracy = loss_0_v.item() / self.test_batch_size\n",
    "        loss = loss_v.item() / self.test_batch_size\n",
    "        return {\"accuracy\": accuracy, \"loss_H2\": loss}\n",
    "\n",
    "    # def metrics_test_cases(self) -> dict:\n",
    "    #     metrics = self.metrics_test_case(1)\n",
    "    #     accuracy = metrics[\"accuracy\"]\n",
    "    #     loss = metrics[\"loss_H2\"]\n",
    "    #     return {\"accuracy\": accuracy, \"loss_H2\": loss}\n",
    "\n",
    "    def score_test_cases(self):\n",
    "        # on s√©lectionnera les agents avec le score le plus grand possible (donc si on veut mettre la crossentropy, il faut ajouter un signe -)\n",
    "        return -self.metrics_test_case(0)[\"accuracy\"]\n",
    "\n",
    "    # facultatif\n",
    "    def plot_train_case(self, ax, case, custom_args=None):\n",
    "        ax.plot(self.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data = DataLoader(False)\n",
    "    gU = GridupTrainer(\n",
    "        Agent,\n",
    "        agent_params={\n",
    "            \"level\": (2, [0, 1, 2]),\n",
    "            \"initial_lr\": (5e-3, [1e-2, 5e-3, 2e-3, 1e-3, 5e-4], True),\n",
    "            \"n_modes\": (10, [10, 15, 20, 25], True),\n",
    "            \"width\": (20, [10, 15, 20, 25], True),\n",
    "            \"batch_size\": (32, [32, 64], True),\n",
    "            \"l2_lambda\": (1e-3, [0.0, 1e-2, 1e-3, 1e-4], True),\n",
    "            \"pad_prop\": (0.05, [0.0, 0.05, 0.025], True),\n",
    "            \"pad_mode\": (\"reflect\", [\"reflect\", \"constant\"], True),\n",
    "            \"essaie\": (1, [1, 2, 3], True),\n",
    "        },\n",
    "        agent_const={\n",
    "            \"data\": data,\n",
    "        },\n",
    "        cases_for_train=[1],\n",
    "        cases_for_test=[1],\n",
    "        train_duration_for_one_agent=\"2000 steps\",\n",
    "        verbose=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_result = gU.random_search(minutes=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random_search_result.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = random_search_result.df\n",
    "dataframe.to_csv(\"./results.csv\")\n",
    "print(dataframe.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random_search_result.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_result = gU.random_search_around(minutes=40, proba=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random_search_result.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random_search_result.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_search_result = gU.one_param_search(\"n_modes\")\n",
    "print(param_search_result.df)\n",
    "param_search_result.compare_scores()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fenics_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
