{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import torch \n",
    "\n",
    "seed = 2023\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "import dolfin as df\n",
    "import time\n",
    "from utils import *\n",
    "from utils_training import *\n",
    "import prepare_data\n",
    "from utils_compare_methods import *\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from prepare_data import rotate, outside_ball\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "sns.set_theme()\n",
    "sns.set_context(\"paper\")\n",
    "colors = sns.color_palette(\"mako\").as_hex()\n",
    "my_cmap = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs = True\n",
    "small_data = False\n",
    "data = DataLoader(small_data)\n",
    "\n",
    "agent_H2 = Agent(\n",
    "    data,\n",
    "    level=2,\n",
    "    relative=True,\n",
    "    squared=False,\n",
    "    initial_lr=5e-3,\n",
    "    n_modes=10,\n",
    "    width=20,\n",
    "    batch_size=32,\n",
    "    pad_prop=0.05,\n",
    "    pad_mode=\"reflect\",\n",
    "    l2_lambda=1e-3,\n",
    ")\n",
    "model_H2 = agent_H2.model\n",
    "device = agent_H2.device\n",
    "\n",
    "models_repo_H2 = \"./models_H2\"\n",
    "images_repo = \"./images\"\n",
    "best_model_H2 = torch.load(f\"{models_repo_H2}/best_model.pkl\")\n",
    "model_H2.load_state_dict(best_model_H2[\"model_state_dict\"])\n",
    "model_H2.eval()\n",
    "print(f\"Best epoch H2 = {best_model_H2['epoch']}\")\n",
    "\n",
    "agent_H1 = Agent(\n",
    "    data,\n",
    "    level=1,\n",
    "    relative=True,\n",
    "    squared=False,\n",
    "    initial_lr=5e-3,\n",
    "    n_modes=10,\n",
    "    width=20,\n",
    "    batch_size=32,\n",
    "    pad_prop=0.05,\n",
    "    pad_mode=\"reflect\",\n",
    "    l2_lambda=1e-3,\n",
    ")\n",
    "model_H1 = agent_H1.model\n",
    "device = agent_H1.device\n",
    "\n",
    "models_repo_H1 = \"./models_H1\"\n",
    "images_repo = \"./images\"\n",
    "best_model_H1 = torch.load(f\"{models_repo_H1}/best_model.pkl\")\n",
    "model_H1.load_state_dict(best_model_H1[\"model_state_dict\"])\n",
    "model_H1.eval()\n",
    "\n",
    "print(f\"Best epoch H1 = {best_model_H1['epoch']}\")\n",
    "\n",
    "agent_L2 = Agent(\n",
    "    data,\n",
    "    level=0,\n",
    "    relative=True,\n",
    "    squared=False,\n",
    "    initial_lr=5e-3,\n",
    "    n_modes=10,\n",
    "    width=20,\n",
    "    batch_size=32,\n",
    "    pad_prop=0.05,\n",
    "    pad_mode=\"reflect\",\n",
    "    l2_lambda=1e-3,\n",
    ")\n",
    "model_L2 = agent_L2.model\n",
    "device = agent_L2.device\n",
    "\n",
    "models_repo_L2 = \"./models_l2\"\n",
    "images_repo = \"./images\"\n",
    "best_model_L2 = torch.load(f\"{models_repo_L2}/best_model.pkl\")\n",
    "model_L2.load_state_dict(best_model_L2[\"model_state_dict\"])\n",
    "model_L2.eval()\n",
    "\n",
    "print(f\"Best epoch l2 = {best_model_L2['epoch']}\")\n",
    "\n",
    "\n",
    "if not (os.path.exists(f\"{images_repo}/\")) and save_figs:\n",
    "    os.makedirs(f\"{images_repo}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With respect to a $\\phi$-FEM solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_data import PhiFemSolver\n",
    "from prepare_data import set_seed\n",
    "\n",
    "set_seed(16012023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test, x_normed, Y_pred, X_denormed = None, None, None, None, None\n",
    "X_val, Y_val = None, None\n",
    "Phi, G, domain, U_true, U_pred = None, None, None, None, None\n",
    "error, magnitude, error_inf, magnitude_inf = None, None, None, None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()  # PyTorch thing\n",
    "\n",
    "nb_test_data = 10000\n",
    "if not os.path.exists(f\"./data_test_phi_fem_{nb_test_data}\"):\n",
    "    os.makedirs(f\"./data_test_phi_fem_{nb_test_data}\")\n",
    "    F, Phi, G, params = create_FG_numpy(nb_test_data, 64)\n",
    "    print(\"Parameters generated\")\n",
    "    solver = PhiFemSolver(nb_cell=64 - 1, params=params)\n",
    "    W_phi_fem = solver.solve_several()\n",
    "    X_test = generate_manual_new_data_numpy(F, Phi, G).to(device)\n",
    "\n",
    "    np.save(f\"./data_test_phi_fem_{nb_test_data}/F.npy\", F)\n",
    "    np.save(f\"./data_test_phi_fem_{nb_test_data}/agentParams.npy\", params)\n",
    "    np.save(f\"./data_test_phi_fem_{nb_test_data}/Phi.npy\", Phi)\n",
    "    np.save(f\"./data_test_phi_fem_{nb_test_data}/G.npy\", G)\n",
    "    np.save(f\"./data_test_phi_fem_{nb_test_data}/W.npy\", W_phi_fem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test, x_normed, Y_pred, X_denormed = None, None, None, None, None\n",
    "Phi, G, domain, U_true, U_pred = None, None, None, None, None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()  # PyTorch thing\n",
    "\n",
    "F, Phi, G = (\n",
    "    np.load(f\"./data_test_phi_fem_{nb_test_data}/F.npy\"),\n",
    "    np.load(f\"./data_test_phi_fem_{nb_test_data}/Phi.npy\"),\n",
    "    np.load(f\"./data_test_phi_fem_{nb_test_data}/G.npy\"),\n",
    ")\n",
    "W_phi_fem = np.load(f\"./data_test_phi_fem_{nb_test_data}/W.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_L2_norm_squared(U, domain):\n",
    "    nb_vertices = torch.sum(domain, (1, 2), False)\n",
    "    norm = (1.0 / nb_vertices) * torch.sum(U**2 * domain, (1, 2), False)\n",
    "    return norm\n",
    "\n",
    "\n",
    "def compute_Linf_norm(U, domain):\n",
    "    norm = torch.amax(torch.abs(U * domain), (1, 2))\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_error_H2, L2_error_H1, L2_error_L2 = [], [], []\n",
    "test_batch_size = 100\n",
    "nb_test_batch = nb_test_data // test_batch_size\n",
    "print(f\"{test_batch_size=}\")\n",
    "print(f\"{nb_test_batch=}\")\n",
    "\n",
    "for j in range(nb_test_batch):\n",
    "    print(f\"Batch : {j} / {nb_test_batch}\")\n",
    "    X_test, Y_test, x_normed, Y_pred, X_denormed = None, None, None, None, None\n",
    "    domain, U_true, U_pred_H2, U_pred_H1, U_pred_L2 = None, None, None, None, None\n",
    "    (\n",
    "        X_test_normed_j,\n",
    "        Y_pred_normed_j_H2,\n",
    "        Y_pred_normed_j_H1,\n",
    "        Y_pred_normed_j_L2,\n",
    "        Y_pred,\n",
    "        Phi_batch,\n",
    "        Y_test_batch,\n",
    "        G_batch,\n",
    "    ) = (None, None, None, None, None, None, None, None)\n",
    "    error, magnitude, error_inf, magnitude_inf = None, None, None, None\n",
    "    error_H1, error_H2, error_L2 = None, None, None\n",
    "    model = None  # clear memory\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()  # PyTorch thing\n",
    "\n",
    "    model_H2.eval()\n",
    "    model_H1.eval()\n",
    "    model_L2.eval()\n",
    "\n",
    "    sli = slice(j * test_batch_size, (j + 1) * test_batch_size)\n",
    "    X_test = generate_manual_new_data_numpy(F[sli], Phi[sli], G[sli]).to(device)\n",
    "    X_test_normed_j = data.x_normalizer.encode(X_test)\n",
    "    Phi_batch, G_batch = X_test[:, 1, :, :], X_test[:, 2, :, :]\n",
    "    domain = (Phi_batch <= 3e-16).to(device)\n",
    "    Y_test_batch = torch.tensor(W_phi_fem[sli, None, :, :]).to(device)\n",
    "    U_true = Y_test_batch[:, 0, :, :] * Phi_batch + G_batch\n",
    "    magnitude = compute_L2_norm_squared((U_true), domain)\n",
    "\n",
    "    # eval\n",
    "    Y_pred_normed_j_H2 = model_H2(X_test_normed_j)\n",
    "    Y_pred_H2 = data.y_normalizer.decode(Y_pred_normed_j_H2)\n",
    "    U_pred_H2 = Y_pred_H2[:, 0, :, :] * Phi_batch + G_batch\n",
    "\n",
    "    error_H2 = compute_L2_norm_squared((U_pred_H2 - U_true), domain)\n",
    "    L2_error_batch_H2 = torch.sqrt(error_H2 / magnitude).cpu().detach().numpy()\n",
    "    L2_error_H2.append(L2_error_batch_H2)\n",
    "\n",
    "    U_pred_H2 = None\n",
    "    Y_pred_normed_j_H2, Y_pred_H2 = None, None\n",
    "    error_H2, L2_error_batch_H2 = None, None\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()  # PyTorch thing\n",
    "\n",
    "    Y_pred_normed_j_H1 = model_H1(X_test_normed_j)\n",
    "    Y_pred_H1 = data.y_normalizer.decode(Y_pred_normed_j_H1)\n",
    "    U_pred_H1 = Y_pred_H1[:, 0, :, :] * Phi_batch + G_batch\n",
    "\n",
    "    error_H1 = compute_L2_norm_squared((U_pred_H1 - U_true), domain)\n",
    "    L2_error_batch_H1 = torch.sqrt(error_H1 / magnitude).cpu().detach().numpy()\n",
    "    L2_error_H1.append(L2_error_batch_H1)\n",
    "\n",
    "    U_pred_H1 = None\n",
    "    Y_pred_normed_j_H1, Y_pred_H1 = None, None\n",
    "    error_H1, L2_error_batch_H1 = None, None\n",
    "\n",
    "    Y_pred_normed_j_L2 = model_L2(X_test_normed_j)\n",
    "    Y_pred_L2 = data.y_normalizer.decode(Y_pred_normed_j_L2)\n",
    "    U_pred_L2 = Y_pred_L2[:, 0, :, :] * Phi_batch + G_batch\n",
    "\n",
    "    error_L2 = compute_L2_norm_squared((U_pred_L2 - U_true), domain)\n",
    "    L2_error_batch_L2 = torch.sqrt(error_L2 / magnitude).cpu().detach().numpy()\n",
    "    L2_error_L2.append(L2_error_batch_L2)\n",
    "\n",
    "    U_pred_L2 = None\n",
    "    Y_pred_normed_j_L2, Y_pred_L2 = None, None\n",
    "    error_L2, L2_error_batch_L2 = None, None\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()  # PyTorch thing\n",
    "\n",
    "L2_error_H2 = np.array(L2_error_H2)\n",
    "L2_error_H2 = L2_error_H2.flatten()\n",
    "\n",
    "L2_error_H1 = np.array(L2_error_H1)\n",
    "L2_error_H1 = L2_error_H1.flatten()\n",
    "\n",
    "L2_error_L2 = np.array(L2_error_L2)\n",
    "L2_error_L2 = L2_error_L2.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_tab = []\n",
    "error_tab.append(L2_error_L2)\n",
    "error_tab.append(L2_error_H1)\n",
    "error_tab.append(L2_error_H2)\n",
    "\n",
    "\n",
    "abs_str = [\n",
    "    r\"FNO $\\mathcal{L}_{L_2}$ loss\",\n",
    "    r\"FNO $\\mathcal{L}_{H_1}$ loss\",\n",
    "    r\"FNO $\\mathcal{L}$ loss\",\n",
    "]\n",
    "errors = np.array(error_tab[:])\n",
    "errors = np.reshape(errors, (3, np.shape(errors)[-1]))\n",
    "print(np.shape(errors))\n",
    "dataframe = pd.DataFrame(errors.transpose(), columns=abs_str)\n",
    "\n",
    "sns.set(font_scale=1.1)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(\n",
    "    data=dataframe,\n",
    "    palette=\"ch:s=.0,rot=0.0,dark=0.5\",\n",
    "    flierprops={\"marker\": \"x\", \"markerfacecolor\": \"black\"},\n",
    ")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Method\", fontsize=16)\n",
    "plt.ylabel(\"Relative $L^2$ error\", fontsize=16)\n",
    "plt.grid(axis=\"y\", visible=True, which=\"both\")\n",
    "\n",
    "plt.tight_layout()\n",
    "if save_figs:\n",
    "    plt.savefig(f\"{images_repo}/boxplots_compare_losses_L2_phi_FEM.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With respect to a reference solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_loss_levels(param):\n",
    "    standard_solver = StandardFEMSolver(params=param)\n",
    "    mu0, mu1, sigma_x, sigma_y, amplitude, x_0, y_0, lx, ly, theta, alpha, beta = param[\n",
    "        0\n",
    "    ]\n",
    "    u_ref, V_ref, dx_ref = standard_solver.solve_one(0, 0.002, reference_fem=True)\n",
    "\n",
    "    F = generate_F_numpy(mu0, mu1, sigma_x, sigma_y, amplitude, 64)\n",
    "    G = generate_G_numpy(alpha, beta, 64)\n",
    "    phi = generate_phi_numpy(x_0, y_0, lx, ly, theta, 64)\n",
    "    X = generate_manual_new_data_numpy(F, phi, G).to(device)\n",
    "    x_normed = data.x_normalizer.encode(X)\n",
    "\n",
    "    Y_normed_H2 = model_H2(x_normed)\n",
    "    Y_H2 = data.y_normalizer.decode(Y_normed_H2)\n",
    "    predicted_solution_H2 = (\n",
    "        (X[:, 1, :, :] * Y_H2[:, 0, :, :] + X[:, 2, :, :]).cpu().detach().numpy()\n",
    "    )\n",
    "    predicted_solution_H2 = np.reshape(predicted_solution_H2, (64, 64))\n",
    "    predicted_sol_fenics_H2 = convert_numpy_matrix_to_fenics(\n",
    "        predicted_solution_H2, 64, 1\n",
    "    )\n",
    "\n",
    "    predicted_sol_fenics_proj_V_ref_H2 = df.project(\n",
    "        predicted_sol_fenics_H2,\n",
    "        V_ref,\n",
    "        solver_type=\"gmres\",\n",
    "        preconditioner_type=\"hypre_amg\",\n",
    "    )\n",
    "\n",
    "    l2_error_fno_H2 = (\n",
    "        df.assemble((((u_ref - predicted_sol_fenics_proj_V_ref_H2)) ** 2) * dx_ref)\n",
    "        ** (0.5)\n",
    "    ) / (df.assemble((((u_ref)) ** 2) * dx_ref) ** (0.5))\n",
    "\n",
    "    Y_normed_H1 = model_H1(x_normed)\n",
    "    Y_H1 = data.y_normalizer.decode(Y_normed_H1)\n",
    "    predicted_solution_H1 = (\n",
    "        (X[:, 1, :, :] * Y_H1[:, 0, :, :] + X[:, 2, :, :]).cpu().detach().numpy()\n",
    "    )\n",
    "    predicted_solution_H1 = np.reshape(predicted_solution_H1, (64, 64))\n",
    "    predicted_sol_fenics_H1 = convert_numpy_matrix_to_fenics(\n",
    "        predicted_solution_H1, 64, 1\n",
    "    )\n",
    "\n",
    "    predicted_sol_fenics_proj_V_ref_H1 = df.project(\n",
    "        predicted_sol_fenics_H1,\n",
    "        V_ref,\n",
    "        solver_type=\"gmres\",\n",
    "        preconditioner_type=\"hypre_amg\",\n",
    "    )\n",
    "\n",
    "    l2_error_fno_H1 = (\n",
    "        df.assemble((((u_ref - predicted_sol_fenics_proj_V_ref_H1)) ** 2) * dx_ref)\n",
    "        ** (0.5)\n",
    "    ) / (df.assemble((((u_ref)) ** 2) * dx_ref) ** (0.5))\n",
    "\n",
    "    Y_normed_L2 = model_L2(x_normed)\n",
    "    Y_L2 = data.y_normalizer.decode(Y_normed_L2)\n",
    "    predicted_solution_L2 = (\n",
    "        (X[:, 1, :, :] * Y_L2[:, 0, :, :] + X[:, 2, :, :]).cpu().detach().numpy()\n",
    "    )\n",
    "    predicted_solution_L2 = np.reshape(predicted_solution_L2, (64, 64))\n",
    "    predicted_sol_fenics_L2 = convert_numpy_matrix_to_fenics(\n",
    "        predicted_solution_L2, 64, 1\n",
    "    )\n",
    "\n",
    "    predicted_sol_fenics_proj_V_ref_L2 = df.project(\n",
    "        predicted_sol_fenics_L2,\n",
    "        V_ref,\n",
    "        solver_type=\"gmres\",\n",
    "        preconditioner_type=\"hypre_amg\",\n",
    "    )\n",
    "\n",
    "    l2_error_fno_L2 = (\n",
    "        df.assemble((((u_ref - predicted_sol_fenics_proj_V_ref_L2)) ** 2) * dx_ref)\n",
    "        ** (0.5)\n",
    "    ) / (df.assemble((((u_ref)) ** 2) * dx_ref) ** (0.5))\n",
    "\n",
    "    print(f\"{l2_error_fno_H2=:.3e}\")\n",
    "    print(f\"{l2_error_fno_H1=:.3e}\")\n",
    "    print(f\"{l2_error_fno_L2=:.3e}\")\n",
    "\n",
    "    return l2_error_fno_H2, l2_error_fno_H1, l2_error_fno_L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./data_test_compare_methods/\"):\n",
    "    os.makedirs(\"./data_test_compare_methods\")\n",
    "    F, phi, G, params = create_FG_numpy(300, 64)\n",
    "    np.save(\"./data_test_compare_methods/F.npy\", F)\n",
    "    np.save(\"./data_test_compare_methods/Phi.npy\", phi)\n",
    "    np.save(\"./data_test_compare_methods/G.npy\", G)\n",
    "    np.save(\"./data_test_compare_methods/params.npy\", params)\n",
    "else:\n",
    "    F = np.load(\"./data_test_compare_methods/F.npy\")\n",
    "    G = np.load(\"./data_test_compare_methods/G.npy\")\n",
    "    Phi = np.load(\"./data_test_compare_methods/Phi.npy\")\n",
    "    params = np.load(\"./data_test_compare_methods/params.npy\")\n",
    "\n",
    "if not os.path.exists(\"./compare_losses/\"):\n",
    "    os.makedirs(\"./compare_losses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_error_fno_H2, L2_error_fno_H1, L2_error_fno_L2 = [], [], []\n",
    "indices = list(range(0, len(params)))\n",
    "for index in indices:\n",
    "    print(f\"Iter : {index+1}/{len(params)}\")\n",
    "    l2_error_fno_H2, l2_error_fno_H1, l2_error_fno_L2 = compare_loss_levels(\n",
    "        np.array([params[index]])\n",
    "    )\n",
    "    L2_error_fno_H2.append(l2_error_fno_H2)\n",
    "    L2_error_fno_H1.append(l2_error_fno_H1)\n",
    "    L2_error_fno_L2.append(l2_error_fno_L2)\n",
    "    np.save(\n",
    "        f\"./compare_losses/L2_error_fno_H2.npy\",\n",
    "        np.array([L2_error_fno_H2]),\n",
    "    )\n",
    "    np.save(\n",
    "        f\"./compare_losses/L2_error_fno_H1.npy\",\n",
    "        np.array([L2_error_fno_H1]),\n",
    "    )\n",
    "    np.save(\n",
    "        f\"./compare_losses/L2_error_fno_L2.npy\",\n",
    "        np.array([L2_error_fno_L2]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_error_phi_fem = np.load(f\"{models_repo_H2}/L2_error_phi_fem.npy\")\n",
    "L2_error_std_fem = np.load(f\"{models_repo_H2}/L2_error_std_fem.npy\")\n",
    "L2_error_fno_H2 = np.load(f\"compare_losses/L2_error_fno_H2.npy\")\n",
    "L2_error_fno_H1 = np.load(f\"compare_losses/L2_error_fno_H1.npy\")\n",
    "L2_error_fno_L2 = np.load(f\"compare_losses/L2_error_fno_L2.npy\")\n",
    "print(L2_error_fno_L2.shape)\n",
    "print(L2_error_fno_H1.shape)\n",
    "print(L2_error_fno_H2.shape)\n",
    "print(L2_error_std_fem.shape)\n",
    "print(L2_error_phi_fem.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_tab = []\n",
    "error_tab.append(L2_error_phi_fem)\n",
    "error_tab.append(L2_error_std_fem)\n",
    "error_tab.append(L2_error_fno_L2)\n",
    "error_tab.append(L2_error_fno_H1)\n",
    "error_tab.append(L2_error_fno_H2)\n",
    "\n",
    "\n",
    "abs_str = [\n",
    "    r\"$\\phi$-FEM\",\n",
    "    \"Std FEM\",\n",
    "    r\"FNO $\\mathcal{L}_0$\",\n",
    "    r\"FNO $\\mathcal{L}_{H_1}$\",\n",
    "    r\"FNO $\\mathcal{L}$\",\n",
    "]\n",
    "errors = np.array(error_tab[:])\n",
    "errors = np.reshape(errors, (5, np.shape(errors)[-1]))\n",
    "print(np.shape(errors))\n",
    "dataframe = pd.DataFrame(errors.transpose(), columns=abs_str)\n",
    "\n",
    "sns.set(font_scale=1.1)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(\n",
    "    data=dataframe,\n",
    "    palette=\"ch:s=.0,rot=0.0,dark=0.5\",\n",
    "    flierprops={\"marker\": \"x\", \"markerfacecolor\": \"black\"},\n",
    ")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Method\", fontsize=16)\n",
    "plt.ylabel(\"Relative $L^2$ error\", fontsize=16)\n",
    "plt.grid(axis=\"y\", visible=True, which=\"both\")\n",
    "\n",
    "plt.tight_layout()\n",
    "if save_figs:\n",
    "    plt.savefig(f\"{images_repo}/boxplots_compare_losses.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fenics_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
