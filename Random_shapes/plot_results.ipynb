{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 2023\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.experimental.numpy.random.seed(seed)\n",
    "os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
    "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "# Set a fixed value for the hash seed\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "import dolfin as df\n",
    "import time\n",
    "from utils import *\n",
    "from utils_training import *\n",
    "import prepare_data\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import pandas as pd\n",
    "\n",
    "sns.set_theme()\n",
    "sns.set_context(\"paper\")\n",
    "sns.set(rc={\"xtick.bottom\": True, \"ytick.left\": True})\n",
    "colors = sns.color_palette(\"mako\").as_hex()\n",
    "my_cmap = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     for gpu in gpus:\n",
    "#         tf.config.experimental.set_virtual_device_configuration(gpu,[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_data_origin = 2811\n",
    "nb_data_used = 2811\n",
    "save_figs = True\n",
    "\n",
    "small_data = False  # False=>on utilise toutes les données\n",
    "if not (small_data):\n",
    "    nb_data_used = nb_data_origin\n",
    "level = 2\n",
    "data = DataLoader(small_data)\n",
    "agent = Agent(data, small_data)\n",
    "\n",
    "if not (os.path.exists(f\"./images_{nb_data_used}/\")) and save_figs:\n",
    "    os.makedirs(f\"./images_{nb_data_used}/\")\n",
    "\n",
    "epochs = [100, 200, 500, 750, 1000, 1250, 1500, 2000]\n",
    "print(len(epochs))\n",
    "print(epochs)\n",
    "\n",
    "indices = list(range(0, len(epochs)))\n",
    "size_per_fig = 4\n",
    "nb_rows = 2\n",
    "size_row = int(len(indices) / nb_rows)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erreur minimale d'un modèle sur le jeu de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2000\n",
    "agent.model.load_weights(f\"./models_{nb_data_used}/model_{i}/model_weights\")\n",
    "X_val, Y_val = agent.data.X_val, agent.data.Y_val\n",
    "Y_pred = agent.model.call(X_val)\n",
    "domain = X_val[:, :, :, -2]\n",
    "boundary = X_val[:, :, :, -1]\n",
    "nb_vert = np.shape(boundary)[1]\n",
    "domain_prop = tf.reduce_sum(domain, axis=[1, 2]) / nb_vert**2\n",
    "boundary_prop = tf.reduce_sum(boundary, axis=[1, 2]) / nb_vert**2\n",
    "\n",
    "diff = (Y_val - Y_pred) * X_val[:, :, :, 1, None]\n",
    "\n",
    "L2_error = tf.sqrt(\n",
    "    tf.reduce_mean(\n",
    "        (diff**2)\n",
    "        * X_val[:, :, :, -2, None]\n",
    "        / (domain_prop[:, None, None, None]),\n",
    "        axis=[1, 2, 3],\n",
    "    )\n",
    "    / tf.reduce_mean(\n",
    "        ((Y_val * X_val[:, :, :, 1, None]) ** 2)\n",
    "        * X_val[:, :, :, -2, None]\n",
    "        / (domain_prop[:, None, None, None]),\n",
    "        axis=[1, 2, 3],\n",
    "    )\n",
    ")\n",
    "\n",
    "argmin = np.argmin(L2_error)\n",
    "print(argmin)\n",
    "sorted_min = sorted(range(len(L2_error)), key=lambda k: L2_error[k])\n",
    "minimal_errors = sorted_min[:1]\n",
    "print(minimal_errors)\n",
    "\n",
    "\n",
    "Params = np.load(f\"./data_{nb_data_origin}_3_modes/agentParams.npy\")[\n",
    "    0:nb_data_used\n",
    "]\n",
    "data_size = np.shape(Params)[0]\n",
    "nb_val = data_size // 8\n",
    "nb_train = data_size - nb_val\n",
    "params_val = Params[nb_train:]\n",
    "\n",
    "\n",
    "for i in minimal_errors:\n",
    "    X = data.X_val[i, :, :]\n",
    "    F = X[:, :, 0] * data.max_norm_F\n",
    "    U_ref = data.Y_val[i]\n",
    "    Y = agent.model.call(X[None, :, :, :])\n",
    "\n",
    "    domains_nan = X[:, :, -2].numpy()\n",
    "    domains_nan[domains_nan == 0] = np.nan\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    ax1 = plt.subplot(131)\n",
    "    img = ax1.imshow(\n",
    "        F * domains_nan, cmap=my_cmap, aspect=\"equal\", origin=\"lower\"\n",
    "    )\n",
    "    divider = make_axes_locatable(ax1)\n",
    "    cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.3)\n",
    "    ax1.grid(False)\n",
    "    ax1.set_title(r\"$f$\", fontsize=20)\n",
    "    plt.colorbar(img, cax=cax, orientation=\"horizontal\")\n",
    "\n",
    "    ax2 = plt.subplot(132)\n",
    "    img = ax2.imshow(\n",
    "        Y[0, :, :, 0] * X[:, :, 1] * domains_nan,\n",
    "        cmap=my_cmap,\n",
    "        aspect=\"equal\",\n",
    "        origin=\"lower\",\n",
    "    )\n",
    "    divider = make_axes_locatable(ax2)\n",
    "    cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.3)\n",
    "    ax2.grid(False)\n",
    "    ax2.set_title(r\"$\\phi w_{pred}$\", fontsize=20)\n",
    "    plt.colorbar(img, cax=cax, orientation=\"horizontal\")\n",
    "\n",
    "    ax3 = plt.subplot(133)\n",
    "    img = ax3.imshow(\n",
    "        U_ref[:, :, 0] * X[:, :, 1] * domains_nan,\n",
    "        cmap=my_cmap,\n",
    "        aspect=\"equal\",\n",
    "        origin=\"lower\",\n",
    "    )\n",
    "    divider = make_axes_locatable(ax3)\n",
    "    cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.3)\n",
    "    ax3.grid(False)\n",
    "    ax3.set_title(r\"$\\phi w_{ref}$\", fontsize=20)\n",
    "    plt.colorbar(img, cax=cax, orientation=\"horizontal\")\n",
    "\n",
    "    if save_figs:\n",
    "        plt.savefig(\n",
    "            f\"./images_{nb_data_used}/best_prediction_{L2_error[i]:6f}.png\"\n",
    "        )\n",
    "    plt.show()\n",
    "\n",
    "    params = params_val[i]\n",
    "    print(f\"(mu0, mu1, sigma, x_0, y_0, lx, ly, theta) = {params}\")\n",
    "    print(f\"{L2_error[i]:6f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erreur relative en fonction des epochs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jeu de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "Linf_errors = []\n",
    "\n",
    "for i in epochs:\n",
    "    agent.model.load_weights(\n",
    "        f\"./models_{nb_data_used}/model_{i}/model_weights\"\n",
    "    )\n",
    "    X_val, Y_val = agent.data.X_val, agent.data.Y_val\n",
    "    Y_pred = agent.model.call(X_val)\n",
    "    domain = X_val[:, :, :, -2]\n",
    "    boundary = X_val[:, :, :, -1]\n",
    "    nb_vert = np.shape(boundary)[1]\n",
    "    domain_prop = tf.reduce_sum(domain, axis=[1, 2]) / nb_vert**2\n",
    "    boundary_prop = tf.reduce_sum(boundary, axis=[1, 2]) / nb_vert**2\n",
    "\n",
    "    diff = (Y_val - Y_pred) * X_val[:, :, :, 1, None]\n",
    "\n",
    "    val = tf.sqrt(\n",
    "        tf.reduce_mean(\n",
    "            (diff**2)\n",
    "            * X_val[:, :, :, -2, None]\n",
    "            / (domain_prop[:, None, None, None]),\n",
    "            axis=[1, 2, 3],\n",
    "        )\n",
    "        / tf.reduce_mean(\n",
    "            ((Y_val * X_val[:, :, :, 1, None]) ** 2)\n",
    "            * X_val[:, :, :, -2, None]\n",
    "            / (domain_prop[:, None, None, None]),\n",
    "            axis=[1, 2, 3],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    errors.append(val)\n",
    "    Linf_errors.append(\n",
    "        np.max(\n",
    "            np.max(np.absolute(diff * X_val[:, :, :, -2, None]), axis=1),\n",
    "            axis=1,\n",
    "        )\n",
    "        / np.max(\n",
    "            np.max(\n",
    "                np.absolute(\n",
    "                    Y_val * X_val[:, :, :, 1, None] * X_val[:, :, :, -2, None]\n",
    "                ),\n",
    "                axis=1,\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j, k = 0, 0\n",
    "fig, axes = plt.subplots(\n",
    "    nb_rows,\n",
    "    size_row,\n",
    "    figsize=(size_per_fig * size_row, size_per_fig * nb_rows),\n",
    ")\n",
    "\n",
    "for i in range(len(indices)):\n",
    "    if k == size_row:\n",
    "        k = 0\n",
    "        j += 1\n",
    "    sns.histplot(\n",
    "        data=errors[indices[i]],\n",
    "        kde=True,\n",
    "        bins=20,\n",
    "        color=colors[2],\n",
    "        edgecolor=\"k\",\n",
    "        log_scale=True,\n",
    "        label=str(epochs[indices[i]]),\n",
    "        stat=\"proportion\",\n",
    "        legend=True,\n",
    "        ax=axes[j, k],\n",
    "    )\n",
    "    axes[j, k].set_xlabel(\"$L^2$ relative error\")\n",
    "    axes[j, k].legend()\n",
    "    axes[j, k].set_xlim(3e-4, 5e-1)\n",
    "    axes[j, k].set_ylim(0.0, 0.220)\n",
    "    k += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "if save_figs:\n",
    "    plt.savefig(f\"./images_{nb_data_used}/histograms_validation_L2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j, k = 0, 0\n",
    "fig, axes = plt.subplots(\n",
    "    nb_rows,\n",
    "    size_row,\n",
    "    figsize=(size_per_fig * size_row, size_per_fig * nb_rows),\n",
    ")\n",
    "\n",
    "for i in range(len(indices)):\n",
    "    if k == size_row:\n",
    "        k = 0\n",
    "        j += 1\n",
    "    sns.histplot(\n",
    "        data=Linf_errors[indices[i]],\n",
    "        kde=True,\n",
    "        bins=20,\n",
    "        color=colors[2],\n",
    "        edgecolor=\"k\",\n",
    "        log_scale=True,\n",
    "        label=str(epochs[indices[i]]),\n",
    "        stat=\"proportion\",\n",
    "        legend=True,\n",
    "        ax=axes[j, k],\n",
    "    )\n",
    "    axes[j, k].set_xlabel(\"$L^\\infty$ relative error\")\n",
    "    axes[j, k].legend()\n",
    "    axes[j, k].set_xlim(3e-4, 5e-1)\n",
    "    axes[j, k].set_ylim(0.0, 0.220)\n",
    "    k += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "if save_figs:\n",
    "    plt.savefig(f\"./images_{nb_data_used}/histograms_validation_Linf.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "\"\"\"\n",
    "On crée des dataframe de la forme\n",
    "|epoch|error|norm|\n",
    "où type est L2 ou Linf et epoch est un multiple de 250\n",
    "\"\"\"\n",
    "\n",
    "size_val = len(errors[0])\n",
    "\n",
    "epoch_repeat = np.array([])\n",
    "for epoch in epochs:\n",
    "    tab = np.repeat(str(epoch), size_val)\n",
    "    epoch_repeat = np.concatenate([epoch_repeat, tab], axis=0)\n",
    "\n",
    "tab_L2 = np.repeat([\"$L^2$\"], size_val * len(epochs))\n",
    "\n",
    "errors_L2_flatten = np.array(errors).flatten()\n",
    "\n",
    "df_array_L2 = np.stack([epoch_repeat, errors_L2_flatten, tab_L2], axis=0)\n",
    "\n",
    "tab_Linf = np.repeat([\"$L^\\infty$\"], size_val * len(epochs))\n",
    "errors_Linf_flatten = np.array(Linf_errors).flatten()\n",
    "df_array_Linf = np.stack([epoch_repeat, errors_Linf_flatten, tab_Linf], axis=0)\n",
    "\n",
    "df_array = np.concatenate([df_array_L2, df_array_Linf], axis=1)\n",
    "\n",
    "name = [\"Epochs\", \"Error\", \"Norm\"]\n",
    "df_errors = pd.DataFrame(df_array.transpose(), columns=name)\n",
    "df_errors = df_errors.astype(\n",
    "    {\"Epochs\": \"int\", \"Error\": \"float64\", \"Norm\": \"category\"}\n",
    ")\n",
    "\n",
    "sns.boxplot(\n",
    "    data=df_errors, x=\"Epochs\", y=\"Error\", hue=\"Norm\", dodge=True\n",
    ")  # ,palette=\"ch:s=.25,rot=-.25\"\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"Relative error\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_figs:\n",
    "    plt.savefig(f\"./images_{nb_data_used}/boxplots_validation_L2_Linf.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "errors = np.array(errors[:])\n",
    "print(np.shape(errors))\n",
    "dataframe = pd.DataFrame(errors.transpose(), columns=epochs)\n",
    "\n",
    "sns.boxplot(data=dataframe, palette=\"ch:s=.25,rot=-.25\")\n",
    "plt.xlabel(\"Training epochs\")\n",
    "plt.ylabel(\"$L^2$ relative error\")\n",
    "plt.yscale(\"log\")\n",
    "plt.grid(True, \"both\", \"y\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"./images_{nb_data_used}/boxplots_validation_epochs_L2_error.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_means = list(i * 50 for i in range(1, 41))\n",
    "\n",
    "print(len(epochs_means))\n",
    "print(epochs_means)\n",
    "\n",
    "errors = []\n",
    "Linf_errors = []\n",
    "\n",
    "for i in epochs_means:\n",
    "    agent.model.load_weights(\n",
    "        f\"./models_{nb_data_used}/model_{i}/model_weights\"\n",
    "    )\n",
    "    X_val, Y_val = agent.data.X_val, agent.data.Y_val\n",
    "    Y_pred = agent.model.call(X_val)\n",
    "    domain = X_val[:, :, :, -2]\n",
    "    boundary = X_val[:, :, :, -1]\n",
    "    nb_vert = np.shape(boundary)[1]\n",
    "    domain_prop = tf.reduce_sum(domain, axis=[1, 2]) / nb_vert**2\n",
    "    boundary_prop = tf.reduce_sum(boundary, axis=[1, 2]) / nb_vert**2\n",
    "\n",
    "    diff = Y_val * X_val[:, :, :, 1, None] - (Y_pred * X_val[:, :, :, 1, None])\n",
    "\n",
    "    val = tf.sqrt(\n",
    "        tf.reduce_mean(\n",
    "            (diff**2)\n",
    "            * X_val[:, :, :, -2, None]\n",
    "            / (domain_prop[:, None, None, None]),\n",
    "            axis=[1, 2, 3],\n",
    "        )\n",
    "        / tf.reduce_mean(\n",
    "            ((Y_val * X_val[:, :, :, 1, None]) ** 2)\n",
    "            * X_val[:, :, :, -2, None]\n",
    "            / (domain_prop[:, None, None, None]),\n",
    "            axis=[1, 2, 3],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    errors.append(val)\n",
    "    Linf_errors.append(\n",
    "        np.max(\n",
    "            np.max(np.absolute(diff * X_val[:, :, :, -2, None]), axis=1),\n",
    "            axis=1,\n",
    "        )\n",
    "        / np.max(\n",
    "            np.max(\n",
    "                np.absolute(\n",
    "                    Y_val * X_val[:, :, :, 1, None] * X_val[:, :, :, -2, None]\n",
    "                ),\n",
    "                axis=1,\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.mean(errors, axis=1)\n",
    "standard_deviation = np.std(errors, axis=1)\n",
    "maxs = np.max(errors, axis=1)\n",
    "mins = np.min(errors, axis=1)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.semilogy(epochs_means, means, \"-+\", label=\"Mean\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"$L^2$ relative error\")\n",
    "plt.semilogy(\n",
    "    epochs_means, standard_deviation, \"-+\", label=\"Standard deviation\"\n",
    ")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"$L^2$ relative error\")\n",
    "plt.grid(True, \"both\", \"both\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.semilogy(epochs_means, maxs, \"-+\", label=\"Maximum\")\n",
    "plt.semilogy(epochs_means, mins, \"-+\", label=\"Minimum\")\n",
    "plt.grid(True, \"both\", \"both\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"$L^2$ relative error\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_figs:\n",
    "    plt.savefig(f\"./images_{nb_data_used}/min_mean_max_L2_error_epochs.png\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erreur sur un nouveau jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_data import PhiFemSolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_exs, V_exs, dx_exs = [], [], []\n",
    "L2_error_phi_fem, L2_error_std_fem = [], []\n",
    "Temps_phi, Temps_std = [], []\n",
    "\n",
    "F, Phi, params = create_FG_numpy(300, 64)\n",
    "solver = PhiFemSolver(nb_cell=64 - 1, params=params, phi_vector=Phi)\n",
    "W_phi_fem, Phi_64 = solver.solve_several()\n",
    "print(f\"{np.shape(W_phi_fem)=}\")\n",
    "\n",
    "errors_fno, times_fno = [], []\n",
    "\n",
    "for j in epochs:\n",
    "    print(f\"Epoch : {j}\")\n",
    "    agent.model.load_weights(\n",
    "        f\"./models_{nb_data_used}/model_{j}/model_weights\"\n",
    "    )\n",
    "    L2_error_fno = []\n",
    "    Temps_fno = []\n",
    "    X = generate_manual_new_data_numpy(Phi_64, F / data.max_norm_F)\n",
    "    Y_pred = agent.model.call(X)\n",
    "\n",
    "    domain = X[:, :, :, -2]\n",
    "    boundary = X[:, :, :, -1]\n",
    "    nb_vert = np.shape(boundary)[1]\n",
    "    domain_prop = tf.reduce_sum(domain, axis=[1, 2]) / nb_vert**2\n",
    "    boundary_prop = tf.reduce_sum(boundary, axis=[1, 2]) / nb_vert**2\n",
    "    diff = W_phi_fem[:, :, :] * X[:, :, :, 1] - (\n",
    "        Y_pred[:, :, :, 0] * X[:, :, :, 1]\n",
    "    )\n",
    "\n",
    "    L2_error_fno = tf.sqrt(\n",
    "        tf.reduce_mean(\n",
    "            (diff**2) * X[:, :, :, -2] / (domain_prop[:, None, None]),\n",
    "            axis=[1, 2],\n",
    "        )\n",
    "        / tf.reduce_mean(\n",
    "            ((W_phi_fem * X[:, :, :, 1]) ** 2)\n",
    "            * X[:, :, :, -2]\n",
    "            / (domain_prop[:, None, None]),\n",
    "            axis=[1, 2],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    errors_fno.append(L2_error_fno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j, k = 0, 0\n",
    "fig, axes = plt.subplots(\n",
    "    nb_rows,\n",
    "    size_row,\n",
    "    figsize=(size_per_fig * size_row, size_per_fig * nb_rows),\n",
    ")\n",
    "\n",
    "for i in range(len(indices)):\n",
    "    if k == size_row:\n",
    "        k = 0\n",
    "        j += 1\n",
    "    sns.histplot(\n",
    "        data=errors_fno[indices[i]],\n",
    "        kde=True,\n",
    "        bins=20,\n",
    "        color=colors[2],\n",
    "        edgecolor=\"k\",\n",
    "        log_scale=True,\n",
    "        label=str(epochs[indices[i]]),\n",
    "        stat=\"proportion\",\n",
    "        legend=True,\n",
    "        ax=axes[j, k],\n",
    "    )\n",
    "    axes[j, k].set_xlabel(\"$L^2$ relative error\")\n",
    "    axes[j, k].legend()\n",
    "    axes[j, k].set_xlim(5e-4, 2e0)\n",
    "    axes[j, k].set_ylim(0.0, 0.24)\n",
    "    k += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "if save_figs:\n",
    "    plt.savefig(f\"./images_{nb_data_used}/histograms_new_data_L2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "\"\"\"\n",
    "On crée des dataframe de la forme\n",
    "|epoch|error|norm|\n",
    "où type est L2 ou Linf et epoch est un multiple de 250\n",
    "\"\"\"\n",
    "\n",
    "size_val = len(errors_fno[0])\n",
    "\n",
    "epoch_repeat = np.array([])\n",
    "for epoch in epochs:\n",
    "    tab = np.repeat(str(epoch), size_val)\n",
    "    epoch_repeat = np.concatenate([epoch_repeat, tab], axis=0)\n",
    "\n",
    "tab_L2 = np.repeat([\"$L^2$\"], size_val * len(epochs))\n",
    "\n",
    "errors_L2_flatten = np.array(errors_fno).flatten()\n",
    "\n",
    "df_array_L2 = np.stack([epoch_repeat, errors_L2_flatten, tab_L2], axis=0)\n",
    "\n",
    "df_array = np.concatenate([df_array_L2], axis=1)\n",
    "\n",
    "name = [\"Epochs\", \"Error\", \"Norm\"]\n",
    "df_errors = pd.DataFrame(df_array.transpose(), columns=name)\n",
    "df_errors = df_errors.astype(\n",
    "    {\"Epochs\": \"int\", \"Error\": \"float64\", \"Norm\": \"category\"}\n",
    ")\n",
    "\n",
    "sns.boxplot(\n",
    "    data=df_errors, x=\"Epochs\", y=\"Error\", hue=\"Norm\", dodge=True\n",
    ")  # ,palette=\"ch:s=.25,rot=-.25\"\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"Relative error\")\n",
    "plt.tight_layout()\n",
    "\n",
    "save_figs = True\n",
    "if save_figs:\n",
    "    plt.savefig(f\"./images_{nb_data_used}/boxplots_new_data_L2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_fno = []\n",
    "epochs_means = list(i * 50 for i in range(1, 41))\n",
    "\n",
    "for j in epochs_means:\n",
    "    print(f\"Epoch : {j}\")\n",
    "    agent.model.load_weights(\n",
    "        f\"./models_{nb_data_used}/model_{j}/model_weights\"\n",
    "    )\n",
    "    L2_error_fno = []\n",
    "    Temps_fno = []\n",
    "    X = generate_manual_new_data_numpy(Phi_64, F / data.max_norm_F)\n",
    "    Y_pred = agent.model.call(X)\n",
    "\n",
    "    domain = X[:, :, :, -2]\n",
    "    boundary = X[:, :, :, -1]\n",
    "    nb_vert = np.shape(boundary)[1]\n",
    "    domain_prop = tf.reduce_sum(domain, axis=[1, 2]) / nb_vert**2\n",
    "    boundary_prop = tf.reduce_sum(boundary, axis=[1, 2]) / nb_vert**2\n",
    "    diff = W_phi_fem[:, :, :] * X[:, :, :, 1] - (\n",
    "        Y_pred[:, :, :, 0] * X[:, :, :, 1]\n",
    "    )\n",
    "\n",
    "    L2_error_fno = tf.sqrt(\n",
    "        tf.reduce_mean(\n",
    "            (diff**2) * X[:, :, :, -2] / (domain_prop[:, None, None]),\n",
    "            axis=[1, 2],\n",
    "        )\n",
    "        / tf.reduce_mean(\n",
    "            ((W_phi_fem * X[:, :, :, 1]) ** 2)\n",
    "            * X[:, :, :, -2]\n",
    "            / (domain_prop[:, None, None]),\n",
    "            axis=[1, 2],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    errors_fno.append(L2_error_fno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.mean(errors_fno, axis=1)\n",
    "standard_deviation = np.std(errors_fno, axis=1)\n",
    "maxs = np.max(errors_fno, axis=1)\n",
    "mins = np.min(errors_fno, axis=1)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.semilogy(epochs_means, means, \"-+\", label=\"Mean\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"$L^2$ relative error\")\n",
    "plt.semilogy(\n",
    "    epochs_means, standard_deviation, \"-+\", label=\"Standard deviation\"\n",
    ")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"$L^2$ relative error\")\n",
    "plt.grid(True, \"both\", \"both\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.semilogy(epochs_means, maxs, \"-+\", label=\"Maximum\")\n",
    "plt.semilogy(epochs_means, mins, \"-+\", label=\"Minimum\")\n",
    "plt.grid(True, \"both\", \"both\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"$L^2$ relative error\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_figs:\n",
    "    plt.savefig(\n",
    "        f\"./images_{nb_data_used}/min_mean_max_L2_error_epochs_new_data.png\"\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
