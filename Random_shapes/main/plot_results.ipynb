{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "\n",
    "seed = 2023\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "import dolfin as df\n",
    "import time\n",
    "from utils import *\n",
    "from utils_training import *\n",
    "import prepare_data\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import pandas as pd\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "sns.set_theme()\n",
    "sns.set_context(\"paper\")\n",
    "sns.set(rc={\"xtick.bottom\": True, \"ytick.left\": True})\n",
    "colors = sns.color_palette(\"mako\").as_hex()\n",
    "my_cmap = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization \n",
    "\n",
    "Creation of the data loader and of the agent. Construction of the list containing training steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs = True\n",
    "small_data = False\n",
    "data = DataLoader(small_data)\n",
    "agent = Agent(\n",
    "    data,\n",
    "    level=2,\n",
    "    relative=True,\n",
    "    squared=False,\n",
    "    initial_lr=5e-3,\n",
    "    n_modes=10,\n",
    "    width=20,\n",
    "    batch_size=32,\n",
    "    pad_prop=0.05,\n",
    "    pad_mode=\"reflect\",\n",
    "    l2_lambda=1e-3,\n",
    ")\n",
    "model = agent.model\n",
    "device = agent.device\n",
    "\n",
    "models_repo = \"./models\"\n",
    "images_repo = \"./images\"\n",
    "best_model = torch.load(f\"{models_repo}/best_model.pkl\")\n",
    "\n",
    "print(f\"Best epoch = {best_model['epoch']}\")\n",
    "if not (os.path.exists(f\"{images_repo}/\")) and save_figs:\n",
    "    os.makedirs(f\"{images_repo}/\")\n",
    "\n",
    "epochs = [50, 100, 250, 500, 750, 1000, 1250, 1500, 2000, best_model[\"epoch\"]]\n",
    "print(len(epochs))\n",
    "print(epochs)\n",
    "\n",
    "indices = list(range(0, len(epochs)))\n",
    "size_per_fig = 4\n",
    "nb_rows = 2\n",
    "size_row = int(len(indices) / nb_rows)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal error on the validation sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the $L^2$ relative error of each prediction on the validation sample and determine the minimal error. We represent the data, the prediction and the ground truth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_L2_norm_squared(U, domain):\n",
    "    nb_vertices = torch.sum(domain, (1, 2), False)\n",
    "    norm = (1.0 / nb_vertices) * torch.sum(U**2 * domain, (1, 2), False)\n",
    "    return norm\n",
    "\n",
    "\n",
    "def compute_Linf_norm(U, domain):\n",
    "    norm = torch.amax(torch.abs(U * domain), (1, 2))\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None  # clear memory\n",
    "X_val, Y_val, x_normed, Y_pred, Y_pred_normed, X_val_normed = (\n",
    "    None,\n",
    "    None,\n",
    "    None,\n",
    "    None,\n",
    "    None,\n",
    "    None,\n",
    ")\n",
    "Phi, G, domain, U_true, U_pred = None, None, None, None, None\n",
    "error, magnitude, error_inf, magnitude_inf = None, None, None, None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()  # PyTorch thing\n",
    "\n",
    "\n",
    "model = agent.model\n",
    "best_model = torch.load(f\"{models_repo}/best_model.pkl\")\n",
    "model.load_state_dict(best_model[\"model_state_dict\"])\n",
    "model.eval()\n",
    "\n",
    "X_val, Y_val = data.X_val.to(device), data.Y_val.to(device)\n",
    "X_val_normed = data.X_val_normed.to(device)\n",
    "Y_pred_normed = model(X_val_normed)\n",
    "Y_pred = data.y_normalizer.decode(Y_pred_normed)\n",
    "Phi, G = X_val[:, 1, :, :], X_val[:, 2, :, :]\n",
    "domain = (Phi <= 3e-16).to(device)\n",
    "\n",
    "\n",
    "U_true = Y_val[:, 0, :, :] * Phi + G\n",
    "U_pred = Y_pred[:, 0, :, :] * Phi + G\n",
    "\n",
    "error = compute_L2_norm_squared((U_pred - U_true), domain)\n",
    "magnitude = compute_L2_norm_squared((U_true), domain)\n",
    "L2_error = torch.sqrt(error / magnitude)\n",
    "\n",
    "L2_error = L2_error.cpu().detach().numpy()\n",
    "argmin = np.argmin(L2_error)\n",
    "print(argmin)\n",
    "sorted_min = sorted(range(len(L2_error)), key=lambda k: L2_error[k])\n",
    "minimal_errors = sorted_min[:1]\n",
    "print(minimal_errors)\n",
    "\n",
    "for i in minimal_errors:\n",
    "    model = None  # clear memory\n",
    "    X_val, Y_val, x_normed, Y_pred, Y_pred_normed, X_val_normed = (\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "    )\n",
    "    Phi, G, domain, U_true, U_pred = None, None, None, None, None\n",
    "    error, magnitude, error_inf, magnitude_inf = None, None, None, None\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()  # PyTorch thing\n",
    "\n",
    "    model = agent.model\n",
    "    best_model = torch.load(f\"{models_repo}/best_model.pkl\")\n",
    "    model.load_state_dict(best_model[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "    X = data.X_val[i]\n",
    "    X = X[None, :, :, :].to(device)\n",
    "    X_normed = data.x_normalizer.encode(X)\n",
    "    W_ref = data.Y_val[i].cpu().detach().numpy()\n",
    "    Y_pred_normed = model(X_normed)\n",
    "    Y_pred = data.y_normalizer.decode(Y_pred_normed).cpu().detach().numpy()\n",
    "    F, Phi, G = (\n",
    "        X[0, 0, :, :].cpu().detach().numpy(),\n",
    "        X[0, 1, :, :].cpu().detach().numpy(),\n",
    "        X[0, 2, :, :].cpu().detach().numpy(),\n",
    "    )\n",
    "    domains = Phi <= 3e-16\n",
    "    domains_tmp = domains.flatten()\n",
    "    domains_nan = domains.copy().flatten().astype(float)\n",
    "    domains_nan[np.where(domains_tmp == False)] = np.nan\n",
    "    domains_nan = np.reshape(domains_nan, domains.shape)\n",
    "    plt.figure(figsize=(16, 4))\n",
    "\n",
    "    ax1 = plt.subplot(141)\n",
    "    img = ax1.imshow(F * domains_nan, cmap=my_cmap, aspect=\"equal\", origin=\"lower\")\n",
    "    divider = make_axes_locatable(ax1)\n",
    "    cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.3)\n",
    "    ax1.grid(False)\n",
    "    ax1.set_title(r\"$f$\", fontsize=20)\n",
    "    plt.colorbar(img, cax=cax, orientation=\"horizontal\")\n",
    "\n",
    "    ax2 = plt.subplot(142)\n",
    "    img = ax2.imshow(\n",
    "        G * domains_nan,\n",
    "        cmap=my_cmap,\n",
    "        aspect=\"equal\",\n",
    "        origin=\"lower\",\n",
    "    )\n",
    "    divider = make_axes_locatable(ax2)\n",
    "    cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.3)\n",
    "    ax2.grid(False)\n",
    "    ax2.set_title(r\"$g$\", fontsize=20)\n",
    "    plt.colorbar(img, cax=cax, orientation=\"horizontal\")\n",
    "\n",
    "    ax3 = plt.subplot(143)\n",
    "    img = ax3.imshow(\n",
    "        (Y_pred[0, 0, :, :] * Phi + G) * domains_nan,\n",
    "        cmap=my_cmap,\n",
    "        aspect=\"equal\",\n",
    "        origin=\"lower\",\n",
    "    )\n",
    "    divider = make_axes_locatable(ax3)\n",
    "    cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.3)\n",
    "    ax3.grid(False)\n",
    "    ax3.set_title(r\"$\\phi w_{\\theta} + g$\", fontsize=20)\n",
    "    plt.colorbar(img, cax=cax, orientation=\"horizontal\")\n",
    "\n",
    "    ax4 = plt.subplot(144)\n",
    "    img = ax4.imshow(\n",
    "        (W_ref[0, :, :] * Phi + G) * domains_nan,\n",
    "        cmap=my_cmap,\n",
    "        aspect=\"equal\",\n",
    "        origin=\"lower\",\n",
    "    )\n",
    "    divider = make_axes_locatable(ax4)\n",
    "    cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.3)\n",
    "    ax4.grid(False)\n",
    "    ax4.set_title(r\"$\\phi w_{ref} + g$\", fontsize=20)\n",
    "    plt.colorbar(img, cax=cax, orientation=\"horizontal\")\n",
    "\n",
    "    if save_figs:\n",
    "        plt.savefig(f\"{images_repo}/best_prediction_{L2_error[i]:6f}.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"{L2_error[i]:.3e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relative errors with respect to a $\\phi$-FEM solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then compute the errors (using the same norm and the $L^\\infty$ norm) for the different models, to analyze the convergence of the method on the validation sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_errors_fno = []\n",
    "Linf_errors_fno = []\n",
    "val_batch_size = int(data.nb_val / 2)\n",
    "nb_test_batch = int(data.nb_val // val_batch_size)\n",
    "print(f\"{val_batch_size=}\")\n",
    "print(f\"{nb_test_batch=}\")\n",
    "\n",
    "for i in epochs:\n",
    "    L2_error_i, Linf_error_i = [], []\n",
    "    for j in range(nb_test_batch):\n",
    "        print(f\"Epoch = {i} Batch : {j} / {nb_test_batch}\")\n",
    "        X_test, Y_test, x_normed, Y_pred, X_denormed = None, None, None, None, None\n",
    "        domain, U_true, U_pred = None, None, None\n",
    "        X_test_normed_j, Y_pred_normed_j, Y_pred, Phi_batch, Y_test_batch, G_batch = (\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "        )\n",
    "        error, magnitude, error_inf, magnitude_inf = None, None, None, None\n",
    "        model = None  # clear memory\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()  # PyTorch thing\n",
    "        # F, Phi, G = np.load('./data_test_phi_fem/F.npy'), np.load('./data_test_phi_fem/Phi.npy'), np.load('./data_test_phi_fem/G.npy')\n",
    "        # W_phi_fem = np.load('./data_test_phi_fem/W.npy')\n",
    "        model = agent.model\n",
    "        if i != epochs[-1]:\n",
    "            model_i = torch.load(f\"{models_repo}/model_{i}.pkl\")\n",
    "            model.load_state_dict(model_i[\"model_state_dict\"])\n",
    "        else:\n",
    "            best_model = torch.load(f\"{models_repo}/best_model.pkl\")\n",
    "            model.load_state_dict(best_model[\"model_state_dict\"])\n",
    "        model.eval()\n",
    "        sli = slice(j * val_batch_size, (j + 1) * val_batch_size)\n",
    "        X_test = (data.X_val[sli]).to(device)\n",
    "        X_test_normed_j = data.x_normalizer.encode(X_test)\n",
    "        Y_pred_normed_j = model(X_test_normed_j)\n",
    "        Y_pred = data.y_normalizer.decode(Y_pred_normed_j)\n",
    "\n",
    "        Phi_batch, G_batch = X_test[:, 1, :, :], X_test[:, 2, :, :]\n",
    "        domain = (Phi_batch <= 3e-16).to(device)\n",
    "        Y_test_batch = (data.Y_val[sli]).to(device)\n",
    "        U_true = Y_test_batch[:, 0, :, :] * Phi_batch + G_batch\n",
    "        U_pred = Y_pred[:, 0, :, :] * Phi_batch + G_batch\n",
    "\n",
    "        error = compute_L2_norm_squared((U_pred - U_true), domain)\n",
    "        magnitude = compute_L2_norm_squared((U_true), domain)\n",
    "        L2_error_batch = torch.sqrt(error / magnitude).cpu().detach().numpy()\n",
    "        L2_error_i.append(L2_error_batch)\n",
    "\n",
    "        error_inf = compute_Linf_norm((U_pred - U_true), domain)\n",
    "        magnitude_inf = compute_Linf_norm((U_true), domain)\n",
    "        Linf_error_batch = (error_inf / magnitude_inf).cpu().detach().numpy()\n",
    "        Linf_error_i.append(Linf_error_batch)\n",
    "\n",
    "    L2_error_i = np.array(L2_error_i)\n",
    "    L2_errors_fno.append(L2_error_i.flatten())\n",
    "    Linf_error_i = np.array(Linf_error_i)\n",
    "    Linf_errors_fno.append(Linf_error_i.flatten())\n",
    "\n",
    "\n",
    "L2_errors = np.array(L2_errors_fno)\n",
    "print(L2_errors.shape)\n",
    "Linf_errors = np.array(Linf_errors_fno)\n",
    "print(Linf_errors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None  # clear memory\n",
    "X_val, Y_val, x_normed, Y_pred, X_denormed = None, None, None, None, None\n",
    "Phi, G, domain, U_true, U_pred = None, None, None, None, None\n",
    "error, magnitude, error_inf, magnitude_inf = None, None, None, None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()  # PyTorch thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j, k = 0, 0\n",
    "fig, axes = plt.subplots(\n",
    "    nb_rows,\n",
    "    size_row,\n",
    "    figsize=(size_per_fig * size_row, size_per_fig * nb_rows),\n",
    ")\n",
    "\n",
    "for i in range(len(indices)):\n",
    "    if k == size_row:\n",
    "        k = 0\n",
    "        j += 1\n",
    "\n",
    "    if epochs[indices[i]] == best_model[\"epoch\"]:\n",
    "        color = \"firebrick\"\n",
    "    else:\n",
    "        color = colors[2]\n",
    "    sns.histplot(\n",
    "        data=L2_errors[indices[i]],\n",
    "        kde=True,\n",
    "        bins=30,\n",
    "        color=color,\n",
    "        edgecolor=\"k\",\n",
    "        log_scale=True,\n",
    "        label=str(epochs[indices[i]]),\n",
    "        stat=\"proportion\",\n",
    "        legend=True,\n",
    "        ax=axes[j, k],\n",
    "    )\n",
    "    axes[j, k].set_xlabel(\"$L^2$ relative error\")\n",
    "    axes[j, k].legend()\n",
    "    axes[j, k].set_xlim(1e-4, 2e-1)\n",
    "    axes[j, k].set_ylim(0.0, 0.11)\n",
    "    k += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "if save_figs:\n",
    "    plt.savefig(f\"{images_repo}/histograms_validation_L2.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j, k = 0, 0\n",
    "fig, axes = plt.subplots(\n",
    "    nb_rows,\n",
    "    size_row,\n",
    "    figsize=(size_per_fig * size_row, size_per_fig * nb_rows),\n",
    ")\n",
    "\n",
    "for i in range(len(indices)):\n",
    "    if k == size_row:\n",
    "        k = 0\n",
    "        j += 1\n",
    "\n",
    "    if epochs[indices[i]] == best_model[\"epoch\"]:\n",
    "        color = \"firebrick\"\n",
    "    else:\n",
    "        color = colors[2]\n",
    "    sns.histplot(\n",
    "        data=Linf_errors[indices[i]],\n",
    "        kde=True,\n",
    "        bins=30,\n",
    "        color=color,\n",
    "        edgecolor=\"k\",\n",
    "        log_scale=True,\n",
    "        label=str(epochs[indices[i]]),\n",
    "        stat=\"proportion\",\n",
    "        legend=True,\n",
    "        ax=axes[j, k],\n",
    "    )\n",
    "    axes[j, k].set_xlabel(\"$L^\\infty$ relative error\")\n",
    "    axes[j, k].legend()\n",
    "    axes[j, k].set_xlim(1e-4, 1e-1)\n",
    "    # axes[j, k].set_ylim(0.0, 0.11)\n",
    "    k += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "if save_figs:\n",
    "    plt.savefig(f\"{images_repo}/histograms_validation_Linf.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "size_val = len(L2_errors[0])\n",
    "\n",
    "epoch_repeat = np.array([])\n",
    "for epoch in epochs:\n",
    "    tab = np.repeat(str(epoch), size_val)\n",
    "    epoch_repeat = np.concatenate([epoch_repeat, tab], axis=0)\n",
    "\n",
    "tab_L2 = np.repeat([\"$L^2$\"], size_val * len(epochs))\n",
    "\n",
    "errors_L2_flatten = np.array(L2_errors).flatten()\n",
    "\n",
    "df_array_L2 = np.stack([epoch_repeat, errors_L2_flatten, tab_L2], axis=0)\n",
    "\n",
    "tab_Linf = np.repeat([\"$L^\\infty$\"], size_val * len(epochs))\n",
    "errors_Linf_flatten = np.array(Linf_errors).flatten()\n",
    "df_array_Linf = np.stack([epoch_repeat, errors_Linf_flatten, tab_Linf], axis=0)\n",
    "\n",
    "df_array = np.concatenate([df_array_L2, df_array_Linf], axis=1)\n",
    "\n",
    "name = [\"Epochs\", \"Error\", \"Norm\"]\n",
    "df_errors = pd.DataFrame(df_array.transpose(), columns=name)\n",
    "df_errors = df_errors.astype({\"Epochs\": \"int\", \"Error\": \"float64\", \"Norm\": \"category\"})\n",
    "\n",
    "sns.boxplot(\n",
    "    data=df_errors,\n",
    "    x=\"Epochs\",\n",
    "    y=\"Error\",\n",
    "    hue=\"Norm\",\n",
    "    dodge=True,\n",
    "    order=epochs,\n",
    "    flierprops={\"marker\": \"x\", \"markerfacecolor\": \"black\"},\n",
    ")\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"Relative error\", fontsize=15)\n",
    "plt.xlabel(\"Epochs\", fontsize=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_figs:\n",
    "    plt.savefig(f\"{images_repo}/boxplots_validation_L2_Linf.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.cubehelix_palette(\n",
    "    n_colors=len(epochs) - 1, start=0.25, rot=-0.25, gamma=0.5\n",
    ")\n",
    "palette = palette.as_hex()\n",
    "palette.insert(-1, \"#b22222\")\n",
    "palette = sns.color_palette(palette)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "errors = np.array(L2_errors[:])\n",
    "print(np.shape(errors))\n",
    "dataframe = pd.DataFrame(errors.transpose(), columns=epochs)\n",
    "\n",
    "sns.boxplot(\n",
    "    data=dataframe,\n",
    "    palette=palette,\n",
    "    order=epochs,\n",
    "    flierprops={\"marker\": \"x\", \"markerfacecolor\": \"black\"},\n",
    ")\n",
    "plt.xlabel(\"Training epochs\")\n",
    "plt.ylabel(\"$L^2$ relative error\")\n",
    "plt.yscale(\"log\")\n",
    "plt.grid(True, \"both\", \"y\")\n",
    "plt.tight_layout()\n",
    "if save_figs:\n",
    "    plt.savefig(f\"{images_repo}/boxplots_validation_epochs_L2_error.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_errors_fno = []\n",
    "Linf_errors_fno = []\n",
    "val_batch_size = int(data.nb_val / 2)\n",
    "nb_test_batch = int(data.nb_val // val_batch_size)\n",
    "print(f\"{val_batch_size=}\")\n",
    "print(f\"{nb_test_batch=}\")\n",
    "\n",
    "epochs_means = list(i * 40 for i in range(1, 51))\n",
    "epochs_means.append(best_model[\"epoch\"])\n",
    "\n",
    "for i in epochs_means:\n",
    "    L2_error_i, Linf_error_i = [], []\n",
    "    for j in range(nb_test_batch):\n",
    "        print(f\"Epoch = {i} Batch : {j} / {nb_test_batch}\")\n",
    "        X_test, Y_test, x_normed, Y_pred, X_denormed = None, None, None, None, None\n",
    "        domain, U_true, U_pred = None, None, None\n",
    "        X_test_normed_j, Y_pred_normed_j, Y_pred, Phi_batch, Y_test_batch, G_batch = (\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "        )\n",
    "        error, magnitude, error_inf, magnitude_inf = None, None, None, None\n",
    "        model = None  # clear memory\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()  # PyTorch thing\n",
    "        # F, Phi, G = np.load('./data_test_phi_fem/F.npy'), np.load('./data_test_phi_fem/Phi.npy'), np.load('./data_test_phi_fem/G.npy')\n",
    "        # W_phi_fem = np.load('./data_test_phi_fem/W.npy')\n",
    "        model = agent.model\n",
    "        if i != epochs_means[-1]:\n",
    "            model_i = torch.load(f\"{models_repo}/model_{i}.pkl\")\n",
    "            model.load_state_dict(model_i[\"model_state_dict\"])\n",
    "        else:\n",
    "            best_model = torch.load(f\"{models_repo}/best_model.pkl\")\n",
    "            model.load_state_dict(best_model[\"model_state_dict\"])\n",
    "        model.eval()\n",
    "        sli = slice(j * val_batch_size, (j + 1) * val_batch_size)\n",
    "        X_test = (data.X_val[sli]).to(device)\n",
    "        X_test_normed_j = data.x_normalizer.encode(X_test)\n",
    "        Y_pred_normed_j = model(X_test_normed_j)\n",
    "        Y_pred = data.y_normalizer.decode(Y_pred_normed_j)\n",
    "\n",
    "        Phi_batch, G_batch = X_test[:, 1, :, :], X_test[:, 2, :, :]\n",
    "        domain = (Phi_batch <= 3e-16).to(device)\n",
    "        Y_test_batch = (data.Y_val[sli]).to(device)\n",
    "        U_true = Y_test_batch[:, 0, :, :] * Phi_batch + G_batch\n",
    "        U_pred = Y_pred[:, 0, :, :] * Phi_batch + G_batch\n",
    "\n",
    "        error = compute_L2_norm_squared((U_pred - U_true), domain)\n",
    "        magnitude = compute_L2_norm_squared((U_true), domain)\n",
    "        L2_error_batch = torch.sqrt(error / magnitude).cpu().detach().numpy()\n",
    "        L2_error_i.append(L2_error_batch)\n",
    "\n",
    "        error_inf = compute_Linf_norm((U_pred - U_true), domain)\n",
    "        magnitude_inf = compute_Linf_norm((U_true), domain)\n",
    "        Linf_error_batch = (error_inf / magnitude_inf).cpu().detach().numpy()\n",
    "        Linf_error_i.append(Linf_error_batch)\n",
    "\n",
    "    L2_error_i = np.array(L2_error_i)\n",
    "    L2_errors_fno.append(L2_error_i.flatten())\n",
    "    Linf_error_i = np.array(Linf_error_i)\n",
    "    Linf_errors_fno.append(Linf_error_i.flatten())\n",
    "\n",
    "\n",
    "L2_errors = np.array(L2_errors_fno)\n",
    "print(L2_errors.shape)\n",
    "Linf_errors = np.array(Linf_errors_fno)\n",
    "print(Linf_errors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.mean(L2_errors, axis=1)\n",
    "standard_deviation = np.std(L2_errors, axis=1)\n",
    "maxs = np.max(L2_errors, axis=1)\n",
    "mins = np.min(L2_errors, axis=1)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.semilogy(epochs_means[:-1], means[:-1], \"-+\", label=\"Mean\")\n",
    "plt.semilogy(\n",
    "    epochs_means[:-1],\n",
    "    standard_deviation[:-1],\n",
    "    \"-+\",\n",
    "    label=\"Standard deviation\",\n",
    ")\n",
    "plt.semilogy(epochs_means[-1], means[-1], \"x\", c=\"firebrick\", markersize=6)\n",
    "plt.semilogy(epochs_means[-1], standard_deviation[-1], \"x\", c=\"firebrick\", markersize=6)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.grid(True, \"both\", \"both\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.semilogy(epochs_means[:-1], maxs[:-1], \"-+\", label=\"Maximum\")\n",
    "plt.semilogy(epochs_means[:-1], mins[:-1], \"-+\", label=\"Minimum\")\n",
    "plt.semilogy(epochs_means[-1], maxs[-1], \"x\", c=\"firebrick\", markersize=6)\n",
    "plt.semilogy(epochs_means[-1], mins[-1], \"x\", c=\"firebrick\", markersize=6)\n",
    "plt.grid(True, \"both\", \"both\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"$L^2$ relative error\")\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_figs:\n",
    "    plt.savefig(f\"{images_repo}/min_mean_max_L2_error_epochs.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On a new test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now move to the case of new data. We generate a new dataset and compute the error between a $\\phi$-FEM solution of the dataset and a prediction of the trained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_data import PhiFemSolver\n",
    "from prepare_data import set_seed\n",
    "\n",
    "set_seed(100124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test, x_normed, Y_pred, X_denormed = None, None, None, None, None\n",
    "X_val, Y_val = None, None\n",
    "Phi, G, domain, U_true, U_pred = None, None, None, None, None\n",
    "error, magnitude, error_inf, magnitude_inf = None, None, None, None\n",
    "model = None  # clear memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()  # PyTorch thing\n",
    "\n",
    "nb_test_data = 500\n",
    "n_mode = 3\n",
    "nb_vert = 64\n",
    "test_seed = 160124\n",
    "\n",
    "if not os.path.exists(f\"./data_test_phi_fem_{nb_test_data}\"):\n",
    "    os.makedirs(f\"./data_test_phi_fem_{nb_test_data}\")\n",
    "    F, Phi, G, params = create_FG_numpy(\n",
    "        nb_data=nb_test_data, nb_vert=nb_vert, n_mode=n_mode, seed=test_seed\n",
    "    )\n",
    "    coeffs_ls = np.load(\n",
    "        f\"../data_domains_{n_mode}/params_{nb_test_data}_{test_seed}.npy\"\n",
    "    )\n",
    "\n",
    "    print(\"Parameters generated\")\n",
    "    solver = PhiFemSolver(nb_cell=nb_vert - 1, params=params, coeffs_ls=coeffs_ls)\n",
    "    W_phi_fem = solver.solve_several()\n",
    "    X_test = generate_manual_new_data_numpy(F, Phi, G).to(device)\n",
    "\n",
    "    np.save(f\"./data_test_phi_fem_{nb_test_data}/F.npy\", F)\n",
    "    np.save(f\"./data_test_phi_fem_{nb_test_data}/agentParams.npy\", params)\n",
    "    np.save(f\"./data_test_phi_fem_{nb_test_data}/Phi.npy\", Phi)\n",
    "    np.save(f\"./data_test_phi_fem_{nb_test_data}/G.npy\", G)\n",
    "    np.save(f\"./data_test_phi_fem_{nb_test_data}/W.npy\", W_phi_fem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test, x_normed, Y_pred, X_denormed = None, None, None, None, None\n",
    "Phi, G, domain, U_true, U_pred = None, None, None, None, None\n",
    "model = None  # clear memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()  # PyTorch thing\n",
    "\n",
    "F, Phi, G = (\n",
    "    np.load(f\"./data_test_phi_fem_{nb_test_data}/F.npy\"),\n",
    "    np.load(f\"./data_test_phi_fem_{nb_test_data}/Phi.npy\"),\n",
    "    np.load(f\"./data_test_phi_fem_{nb_test_data}/G.npy\"),\n",
    ")\n",
    "W_phi_fem = np.load(f\"./data_test_phi_fem_{nb_test_data}/W.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_errors_fno = []\n",
    "test_batch_size = 250\n",
    "if test_batch_size <= nb_test_data:\n",
    "    nb_test_batch = nb_test_data // test_batch_size\n",
    "    print(f\"{test_batch_size=}\")\n",
    "    print(f\"{nb_test_batch=}\")\n",
    "else:\n",
    "    nb_test_batch = 1\n",
    "    test_batch_size = nb_test_data\n",
    "\n",
    "for i in epochs:\n",
    "    L2_error_i = []\n",
    "    for j in range(nb_test_batch):\n",
    "        print(f\"Epoch = {i} Batch : {j} / {nb_test_batch}\")\n",
    "        X_test, Y_test, x_normed, Y_pred, X_denormed = None, None, None, None, None\n",
    "        domain, U_true, U_pred = None, None, None\n",
    "        X_test_normed_j, Y_pred_normed_j, Y_pred, Phi_batch, Y_test_batch, G_batch = (\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "        )\n",
    "        error, magnitude, error_inf, magnitude_inf = None, None, None, None\n",
    "        model = None  # clear memory\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()  # PyTorch thing\n",
    "        # F, Phi, G = np.load('./data_test_phi_fem/F.npy'), np.load('./data_test_phi_fem/Phi.npy'), np.load('./data_test_phi_fem/G.npy')\n",
    "        # W_phi_fem = np.load('./data_test_phi_fem/W.npy')\n",
    "        model = agent.model\n",
    "        if i != epochs[-1]:\n",
    "            model_i = torch.load(f\"{models_repo}/model_{i}.pkl\")\n",
    "            model.load_state_dict(model_i[\"model_state_dict\"])\n",
    "        else:\n",
    "            best_model = torch.load(f\"{models_repo}/best_model.pkl\")\n",
    "            model.load_state_dict(best_model[\"model_state_dict\"])\n",
    "        model.eval()\n",
    "        sli = slice(j * test_batch_size, (j + 1) * test_batch_size)\n",
    "        X_test = generate_manual_new_data_numpy(F[sli], Phi[sli], G[sli]).to(device)\n",
    "        X_test_normed_j = data.x_normalizer.encode(X_test)\n",
    "        Y_pred_normed_j = model(X_test_normed_j)\n",
    "        Y_pred = data.y_normalizer.decode(Y_pred_normed_j)\n",
    "\n",
    "        Phi_batch, G_batch = X_test[:, 1, :, :], X_test[:, 2, :, :]\n",
    "        domain = (Phi_batch <= 3e-16).to(device)\n",
    "        Y_test_batch = torch.tensor(W_phi_fem[sli, None, :, :]).to(device)\n",
    "        U_true = Y_test_batch[:, 0, :, :] * Phi_batch + G_batch\n",
    "        U_pred = Y_pred[:, 0, :, :] * Phi_batch + G_batch\n",
    "\n",
    "        error = compute_L2_norm_squared((U_pred - U_true), domain)\n",
    "        magnitude = compute_L2_norm_squared((U_true), domain)\n",
    "        L2_error_batch = torch.sqrt(error / magnitude).cpu().detach().numpy()\n",
    "        L2_error_i.append(L2_error_batch)\n",
    "    L2_error_i = np.array(L2_error_i)\n",
    "    L2_errors_fno.append(L2_error_i.flatten())\n",
    "\n",
    "L2_errors_fno = np.array(L2_errors_fno)\n",
    "print(L2_errors_fno.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j, k = 0, 0\n",
    "fig, axes = plt.subplots(\n",
    "    nb_rows,\n",
    "    size_row,\n",
    "    figsize=(size_per_fig * size_row, size_per_fig * nb_rows),\n",
    ")\n",
    "\n",
    "for i in range(len(indices)):\n",
    "    if k == size_row:\n",
    "        k = 0\n",
    "        j += 1\n",
    "    if epochs[indices[i]] == epochs[-1]:\n",
    "        color = \"firebrick\"\n",
    "    else:\n",
    "        color = colors[2]\n",
    "    sns.histplot(\n",
    "        data=L2_errors_fno[indices[i]],\n",
    "        kde=True,\n",
    "        bins=30,\n",
    "        color=color,\n",
    "        edgecolor=\"k\",\n",
    "        log_scale=True,\n",
    "        label=str(epochs[indices[i]]),\n",
    "        stat=\"proportion\",\n",
    "        legend=True,\n",
    "        ax=axes[j, k],\n",
    "    )\n",
    "    axes[j, k].set_xlabel(\"$L^2$ relative error\")\n",
    "    axes[j, k].legend()\n",
    "    axes[j, k].set_xlim(1e-4, 2e-1)\n",
    "    axes[j, k].set_ylim(0.0, 0.10)\n",
    "    k += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "if save_figs:\n",
    "    plt.savefig(f\"{images_repo}/histograms_new_data_L2_500.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.cubehelix_palette(\n",
    "    n_colors=len(epochs) - 1, start=0.25, rot=-0.25, gamma=0.5\n",
    ")\n",
    "palette = palette.as_hex()\n",
    "palette.insert(-1, \"#b22222\")\n",
    "palette = sns.color_palette(palette)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "errors_fno = np.array(L2_errors_fno[:])\n",
    "print(np.shape(errors_fno))\n",
    "dataframe = pd.DataFrame(errors_fno.transpose(), columns=epochs)\n",
    "\n",
    "sns.boxplot(\n",
    "    data=dataframe,\n",
    "    palette=palette,\n",
    "    order=epochs,\n",
    "    flierprops={\"marker\": \"x\", \"markerfacecolor\": \"black\"},\n",
    ")\n",
    "plt.xlabel(\"Training epochs\")\n",
    "plt.ylabel(\"$L^2$ relative error\")\n",
    "plt.yscale(\"log\")\n",
    "plt.grid(True, \"both\", \"y\")\n",
    "plt.tight_layout()\n",
    "if save_figs:\n",
    "    plt.savefig(f\"{images_repo}/boxplots_new_data_L2_500.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_errors_fno = []\n",
    "L_inf_errors_fno = []\n",
    "\n",
    "for i in epochs_means:\n",
    "    L2_error_i = []\n",
    "    L_inf_error_i = []\n",
    "    for j in range(nb_test_batch):\n",
    "        print(f\"Epoch = {i} Batch : {j} / {nb_test_batch}\")\n",
    "        X_test, Y_test, x_normed, Y_pred, X_denormed = None, None, None, None, None\n",
    "        domain, U_true, U_pred = None, None, None\n",
    "        X_test_normed_j, Y_pred_normed_j, Y_pred, Phi_batch, Y_test_batch, G_batch = (\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "        )\n",
    "        error, magnitude, error_inf, magnitude_inf = None, None, None, None\n",
    "        model = None  # clear memory\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()  # PyTorch thing\n",
    "        model = agent.model\n",
    "        if i != epochs[-1]:\n",
    "            model_i = torch.load(f\"{models_repo}/model_{i}.pkl\")\n",
    "            model.load_state_dict(model_i[\"model_state_dict\"])\n",
    "        else:\n",
    "            best_model = torch.load(f\"{models_repo}/best_model.pkl\")\n",
    "            model.load_state_dict(best_model[\"model_state_dict\"])\n",
    "        model.eval()\n",
    "        sli = slice(j * test_batch_size, (j + 1) * test_batch_size)\n",
    "        X_test = generate_manual_new_data_numpy(F[sli], Phi[sli], G[sli]).to(device)\n",
    "        X_test_normed_j = data.x_normalizer.encode(X_test)\n",
    "        Y_pred_normed_j = model(X_test_normed_j)\n",
    "        Y_pred = data.y_normalizer.decode(Y_pred_normed_j)\n",
    "\n",
    "        Phi_batch, G_batch = X_test[:, 1, :, :], X_test[:, 2, :, :]\n",
    "        domain = (Phi_batch <= 3e-16).to(device)\n",
    "        Y_test_batch = torch.tensor(W_phi_fem[sli, None, :, :]).to(device)\n",
    "        U_true = Y_test_batch[:, 0, :, :] * Phi_batch + G_batch\n",
    "        U_pred = Y_pred[:, 0, :, :] * Phi_batch + G_batch\n",
    "\n",
    "        error = compute_L2_norm_squared((U_pred - U_true), domain)\n",
    "        magnitude = compute_L2_norm_squared((U_true), domain)\n",
    "        L2_error_batch = torch.sqrt(error / magnitude).cpu().detach().numpy()\n",
    "        L2_error_i.append(L2_error_batch)\n",
    "\n",
    "        error_inf = compute_Linf_norm((U_pred - U_true), domain)\n",
    "        magnitude_inf = compute_Linf_norm((U_true), domain)\n",
    "        L_inf_error_batch = (error_inf / magnitude_inf).cpu().detach().numpy()\n",
    "        L_inf_error_i.append(L_inf_error_batch)\n",
    "\n",
    "    L2_error_i = np.array(L2_error_i)\n",
    "    L2_errors_fno.append(L2_error_i.flatten())\n",
    "    L_inf_error_i = np.array(L_inf_error_i)\n",
    "    L_inf_errors_fno.append(L_inf_error_i.flatten())\n",
    "\n",
    "L2_errors_fno = np.array(L2_errors_fno)\n",
    "L_inf_errors_fno = np.array(L_inf_errors_fno)\n",
    "\n",
    "print(L2_errors_fno.shape)\n",
    "print(L_inf_errors_fno.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.mean(L2_errors_fno, axis=1)\n",
    "standard_deviation = np.std(L2_errors_fno, axis=1)\n",
    "maxs = np.max(L2_errors_fno, axis=1)\n",
    "mins = np.min(L2_errors_fno, axis=1)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.semilogy(epochs_means[:-1], means[:-1], \"-+\", label=\"Mean\")\n",
    "plt.semilogy(\n",
    "    epochs_means[:-1],\n",
    "    standard_deviation[:-1],\n",
    "    \"-+\",\n",
    "    label=\"Standard deviation\",\n",
    ")\n",
    "plt.semilogy(epochs_means[-1], means[-1], \"x\", c=\"firebrick\", markersize=6)\n",
    "plt.semilogy(epochs_means[-1], standard_deviation[-1], \"x\", c=\"firebrick\", markersize=6)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.grid(True, \"both\", \"both\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.semilogy(epochs_means[:-1], maxs[:-1], \"-+\", label=\"Maximum\")\n",
    "plt.semilogy(epochs_means[:-1], mins[:-1], \"-+\", label=\"Minimum\")\n",
    "plt.semilogy(epochs_means[-1], maxs[-1], \"x\", c=\"firebrick\", markersize=6)\n",
    "plt.semilogy(epochs_means[-1], mins[-1], \"x\", c=\"firebrick\", markersize=6)\n",
    "plt.grid(True, \"both\", \"both\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"$L^2$ relative error\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_figs:\n",
    "    plt.savefig(f\"{images_repo}/min_mean_max_L2_error_epochs_new_data.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_linf = np.mean(L_inf_errors_fno, axis=1)\n",
    "standard_deviation_linf = np.std(L_inf_errors_fno, axis=1)\n",
    "maxs_linf = np.max(L_inf_errors_fno, axis=1)\n",
    "mins_linf = np.min(L_inf_errors_fno, axis=1)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.semilogy(epochs_means[:-1], means_linf[:-1], \"-+\", label=\"Mean\")\n",
    "plt.semilogy(\n",
    "    epochs_means[:-1],\n",
    "    standard_deviation_linf[:-1],\n",
    "    \"-+\",\n",
    "    label=\"Standard deviation\",\n",
    ")\n",
    "plt.semilogy(epochs_means[-1], means_linf[-1], \"x\", c=\"firebrick\", markersize=6)\n",
    "plt.semilogy(\n",
    "    epochs_means[-1], standard_deviation_linf[-1], \"x\", c=\"firebrick\", markersize=6\n",
    ")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.grid(True, \"both\", \"both\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.semilogy(epochs_means[:-1], maxs_linf[:-1], \"-+\", label=\"Maximum\")\n",
    "plt.semilogy(epochs_means[:-1], mins_linf[:-1], \"-+\", label=\"Minimum\")\n",
    "plt.semilogy(epochs_means[-1], maxs_linf[-1], \"x\", c=\"firebrick\", markersize=6)\n",
    "plt.semilogy(epochs_means[-1], mins_linf[-1], \"x\", c=\"firebrick\", markersize=6)\n",
    "plt.grid(True, \"both\", \"both\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"$L^\\infty$ relative error\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_figs:\n",
    "    plt.savefig(f\"{images_repo}/min_mean_max_Linf_error_epochs_new_data.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
